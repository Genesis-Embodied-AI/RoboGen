{
    "summary": "The code reads a CSV file, preprocesses data, and initializes lists. It finds UIDs for object descriptions using cache or search, returns most similar ones. Verifies candidate object UIDs against target descriptions with Bard's function, adds passing candidates to list, skips if no usable objects found, and saves dictionary in JSON format.",
    "details": [
        {
            "comment": "This code reads a CSV file containing Objaverse object information, removes any rows with missing data, and stores the UIDs, annotations, and corresponding embeddings in separate lists. It then initializes empty lists for tag UIDs, embeddings, and descriptions. The code proceeds to iterate through 31 chunks of default tag UIDs, embeddings, and names, appending them to their respective lists. This data will be used for object recognition and verification.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/objaverse_utils/find_uid_utils.py\":0-22",
            "content": "import pandas as pd\nimport torch\nfrom objaverse_utils.utils import text_to_uid_dict\nfrom gpt_4.verification import check_text_similarity\nimport numpy as np\nfrom gpt_4.bard_verify import verify_objaverse_object\nimport json\nobjaverse_csv = pd.read_csv('objaverse_utils/Cap3D_automated_Objaverse.csv')\nobjaverse_csv = objaverse_csv.dropna()\nobjaverse_csv_uids = list(objaverse_csv.iloc[:, 0].values)\nobjaverse_csv_annotations = list(objaverse_csv.iloc[:, 1].values)\nobjaverse_csv_annotations_embeddings = torch.load(\"objaverse_utils/data/cap3d_sentence_bert_embeddings.pt\")\ntag_uids = []\ntag_embeddings = []\ntag_descriptions = [] \nnum_chunks = 31\nfor idx in range(num_chunks):\n    uids = torch.load(\"objaverse_utils/data/default_tag_uids_{}.pt\".format(idx))\n    embeddings = torch.load(\"objaverse_utils/data/default_tag_embeddings_{}.pt\".format(idx))\n    descriptions = torch.load(\"objaverse_utils/data/default_tag_names_{}.pt\".format(idx))\n    tag_uids = tag_uids + uids\n    tag_descriptions = tag_descriptions + descriptions"
        },
        {
            "comment": "This code finds the UIDs for a given object description. It first checks if the UID is in the cache, and if not, it searches the entire objaverse by calculating similarities between descriptions using embeddings from different chunks. Finally, it sorts the results and returns the UIDs corresponding to the most similar objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/objaverse_utils/find_uid_utils.py\":23-45",
            "content": "    tag_embeddings.append(embeddings)\ndef find_uid(obj_descrption, candidate_num=10, debug=False, task_name=None, task_description=None):\n    uids = text_to_uid_dict.get(obj_descrption, None)\n    all_uid_candidates = text_to_uid_dict.get(obj_descrption + \"_all\", None)\n    if uids is None:\n        print(\"searching whole objaverse for: \", obj_descrption)\n        similarities = []\n        for idx in range(num_chunks):\n            similarity = check_text_similarity(obj_descrption, None, check_embeddings=tag_embeddings[idx])\n            similarity = similarity.flatten()\n            similarities.append(similarity)\n        similarity = check_text_similarity(obj_descrption, None, check_embeddings=objaverse_csv_annotations_embeddings)\n        similarity = similarity.flatten()\n        similarities.append(similarity)\n        similarities = np.concatenate(similarities)\n        all_uids = tag_uids + objaverse_csv_uids\n        all_description = tag_descriptions + objaverse_csv_annotations\n        sorted_idx = np.argsort(similarities)[::-1]"
        },
        {
            "comment": "The code iterates through candidate object UIDs, checks their similarity with the target object description using Bard's verification function. If a candidate passes the check, its UID is added to the usable_uids list. If no usable objects are found, it prints an error message and skips the task.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/objaverse_utils/find_uid_utils.py\":47-61",
            "content": "        usable_uids = []\n        all_uid_candidates = [all_uids[sorted_idx[i]] for i in range(candidate_num)]\n        for candidate_idx in range(candidate_num):\n            print(\"{} candidate {} similarity: {} {}\".format(\"=\" * 10, candidate_idx, similarities[sorted_idx[candidate_idx]], \"=\" * 10))\n            print(\"found uid: \", all_uids[sorted_idx[candidate_idx]])\n            print(\"found description: \", all_description[sorted_idx[candidate_idx]])\n            candidate_uid = all_uids[sorted_idx[candidate_idx]]\n            bard_verify_result = verify_objaverse_object(obj_descrption, candidate_uid, task_name=task_name, task_description=task_description) # TODO: add support for including task name in the checking process\n            print(\"{} Bard thinks this object is usable: {} {}\".format(\"=\" * 20, bard_verify_result, \"=\" * 20))\n            if bard_verify_result:\n                usable_uids.append(candidate_uid)\n        if len(usable_uids) == 0:\n            print(\"no usable objects found for {} skipping this task!!!\".format(obj_descrption))"
        },
        {
            "comment": "Function is populating a dictionary with usable UIDs and saving it to JSON format.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/objaverse_utils/find_uid_utils.py\":62-70",
            "content": "            usable_uids = all_uid_candidates\n        text_to_uid_dict[obj_descrption] = usable_uids\n        text_to_uid_dict[obj_descrption + \"_all\"] = all_uid_candidates\n        with open(\"objaverse_utils/text_to_uid.json\", 'w') as f:\n            json.dump(text_to_uid_dict, f, indent=4)\n        return usable_uids\n    else:\n        return uids"
        }
    ]
}