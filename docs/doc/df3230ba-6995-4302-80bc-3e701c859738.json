{
    "summary": "The code imports the openai library and defines a function called query, which takes system prompt, user, and assistant inputs. It prints content for debugging, uses the OpenAI API to generate responses, appends messages to a list, calculates execution time, and optionally saves results in JSON format.",
    "details": [
        {
            "comment": "This code imports openai, defines a function called query which takes system prompt and user/assistant content as inputs. It then prints the contents for debugging purposes and calls the openAI API with the given model (default is gpt-4). It returns None if debug mode is on.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/query.py\":0-34",
            "content": "import openai\nimport os\nimport time\nimport json\nos.environ[\"OPENAI_API_KEY\"] = os.environ[\"YUFEI_OPENAI_API_KEY\"] # put your api key here\ndef query(system, user_contents, assistant_contents, model='gpt-4', save_path=None, temperature=1, debug=False):\n    for user_content, assistant_content in zip(user_contents, assistant_contents):\n        user_content = user_content.split(\"\\n\")\n        assistant_content = assistant_content.split(\"\\n\")\n        for u in user_content:\n            print(u)\n        print(\"=====================================\")\n        for a in assistant_content:\n            print(a)\n        print(\"=====================================\")\n    for u in user_contents[-1].split(\"\\n\"):\n        print(u)\n    if debug:\n        import pdb; pdb.set_trace()\n        return None\n    print(\"=====================================\")\n    start = time.time()\n    num_assistant_mes = len(assistant_contents)\n    messages = []\n    messages.append({\"role\": \"system\", \"content\": \"{}\".format(system)})\n    for idx in range(num_assistant_mes):"
        },
        {
            "comment": "The code is appending user and assistant messages to a list, setting the OpenAI API key, creating an OpenAI ChatCompletion instance with the model, messages, and temperature, extracting the content from response choices, calculating execution time, printing the result, and optionally saving it in JSON format.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/query.py\":35-58",
            "content": "        messages.append({\"role\": \"user\", \"content\": user_contents[idx]})\n        messages.append({\"role\": \"assistant\", \"content\": assistant_contents[idx]})\n    messages.append({\"role\": \"user\", \"content\": user_contents[-1]})\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    result = ''\n    for choice in response.choices: \n        result += choice.message.content \n    end = time.time()\n    used_time = end - start\n    print(result)\n    if save_path is not None:\n        with open(save_path, \"w\") as f:\n            json.dump({\"used_time\": used_time, \"res\": result, \"system\": system, \"user\": user_contents, \"assistant\": assistant_contents}, f, indent=4)\n    return result"
        }
    ]
}