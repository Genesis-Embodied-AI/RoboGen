{
    "summary": "This code prepares an environment, performs tests/training, executes primitives or rewards based on substep type, saves state, and initializes RoboGen objects for RL algorithms. It creates directories, checks simulation conditions, and allows resumption from saved states with argparse options.",
    "details": [
        {
            "comment": "execute_primitive: builds an environment and executes a primitive, retrying if necessary.\ntest_env: tests the environment with a given solution path and task information.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":0-33",
            "content": "import yaml\nimport os\nfrom RL.ray_learn import run_RL\nimport numpy as np\nimport pybullet as p\nimport time, datetime\nimport json\nfrom manipulation.utils import save_numpy_as_gif, save_env, take_round_images, build_up_env, load_gif\ndef execute_primitive(task_config, solution_path, substep, last_restore_state_file, save_path, \n                      gui=False, randomize=False, obj_id=0):\n    # build the env\n    task_name = substep.replace(\" \", \"_\")\n    env, safe_config = build_up_env(task_config, solution_path, task_name, last_restore_state_file, \n                                    render=gui, randomize=randomize, obj_id=obj_id)\n    env.primitive_save_path = save_path\n    # execute the primitive\n    max_retry = 1\n    cnt = 0\n    # we retry at most 10 times till we get a successful execution.\n    while cnt < max_retry:\n        env.reset()\n        rgbs, states, success = env.execute()\n        if success:\n            break\n        cnt += 1\n    p.disconnect(env.id)\n    return rgbs, states\ndef test_env(solution_path, ti"
        },
        {
            "comment": "This code determines the save path based on whether to move the robot or not, and then creates an environment (env) by building up an environment class with a specific task configuration. It also resets the environment and checks if there is a center point for the environment.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":33-60",
            "content": "me_string, substeps, action_spaces, meta_info, randomize=False, obj_id=0, gui=False, move_robot=False,):\n    if not move_robot:\n        save_path = os.path.join(solution_path, \"blip2\", time_string)\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n    else:\n        save_path = os.path.join(solution_path, \"teaser\", time_string)\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n    substep = substeps[0].lstrip().rstrip()\n    action_space = action_spaces[0].lstrip().rstrip()\n    task_name = substep.replace(\" \", \"_\")\n    env, safe_config = build_up_env(\n        task_config_path, solution_path, task_name, None, return_env_class=False, \n        action_space=action_space,\n        render=gui, randomize=randomize, \n        obj_id=obj_id,\n    )\n    env.reset()\n    center = None\n    if env.use_table:\n        center = np.array([0, 0, 0.4])\n    else:\n        for name in env.urdf_ids:\n            if name in ['robot', 'plane', 'init_table']:\n                continue\n            if env.urdf_types[name] != \"urdf\":"
        },
        {
            "comment": "This code retrieves an object's center and then proceeds to take images from different angles around it. If \"move_robot\" is set, the approach_object function is called first to ensure the robot approaches the object before taking images. The code saves a GIF of all captured images with corresponding metadata. Additionally, it saves the environment state and meta-information to disk for future use.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":61-87",
            "content": "                continue\n            object_id = env.urdf_ids[name]\n            min_aabb, max_aabb = env.get_aabb(object_id)\n            center = (min_aabb + max_aabb) / 2\n            break\n    if center is None:\n        center = np.array([0, 0, 0.4])\n    name = None\n    for obj_name in env.urdf_types:\n        if env.urdf_types[obj_name] == \"urdf\":\n            name = obj_name\n            break\n    if move_robot:\n        from manipulation.gpt_primitive_api import approach_object\n        env.primitive_save_path = save_path\n        primitive_rgbs, primitive_states = approach_object(env, name)\n    rgbs, depths = take_round_images(env, center=center, distance=1.6, azimuth_interval=5)\n    if move_robot:\n        all_rgbs = primitive_rgbs + rgbs\n    else:\n        all_rgbs = rgbs\n    save_numpy_as_gif(np.array(all_rgbs), \"{}/{}.gif\".format(save_path, \"construction\"), fps=10)\n    save_env(env, os.path.join(save_path, \"env.pkl\"))\n    with open(os.path.join(save_path, \"meta_info.json\"), 'w') as f:\n        json.dump(meta_info, f)"
        },
        {
            "comment": "This function takes in various configuration parameters such as task file path, time string (optional), and whether to resume training. It also includes options for algorithm selection, GUI usage, randomization of initial state, using Bard for verification, and utilizing data from GPT. Additionally, it has options for running training, selecting an object, enabling motion planning, using a distractor, and skipping substeps.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":88-105",
            "content": "    return \ndef execute(task_config_path, \n            time_string=None, resume=False, # these two are combined for resume training.\n            training_algo='RL_sac', \n            gui=False, \n            randomize=False, # whether to randomize the initial state of the environment.\n            use_bard=True, # whether to use the bard to verify the retrieved objects.\n            use_gpt_size=True, # whether to use the size from gpt.\n            use_gpt_joint_angle=True, # whether to initialize the joint angle from gpt.\n            use_gpt_spatial_relationship=True, # whether to use the spatial relationship from gpt.\n            run_training=True, # whether to actually train the policy or just build the environment.\n            obj_id=0, # which object to use from the list of possible objects.\n            use_motion_planning=True,\n            use_distractor=False,\n            skip=[], # which substeps to skip.\n            move_robot=False, # whether to move the robot to the initial state.\n            only_learn_substep=None,"
        },
        {
            "comment": "This code is initializing variables, reading a task configuration file using yaml format and creating required directories. It also checks if the solution path exists, and if not, it creates the directories for solution and experiment paths. The code will be executed in a function that seems to relate to RoboGen's execution process.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":106-139",
            "content": "            reward_learning_save_path=None,\n            last_restore_state_file=None,\n):\n    if time_string is None:\n        ts = time.time()\n        time_string = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n    meta_info = {\n        \"using_motion_planning\": use_motion_planning,\n        \"using_bard\": use_bard,\n        \"using_gpt_size\": use_gpt_size,\n        \"using_gpt_joint_angle\": use_gpt_joint_angle,\n        \"using_gpt_spatial_relationship\": use_gpt_spatial_relationship,\n        \"obj_id\": obj_id,\n        \"use_distractor\": use_distractor\n    }\n    all_last_state_files = []\n    with open(task_config_path, 'r') as file:\n        task_config = yaml.safe_load(file)\n    solution_path = None\n    for obj in task_config:\n        if \"solution_path\" in obj:\n            solution_path = obj[\"solution_path\"]\n            break\n    if not os.path.exists(solution_path):\n        os.makedirs(solution_path, exist_ok=True)\n    experiment_path = os.path.join(solution_path, \"experiment\")\n    if not os.path.exists(experiment_path):"
        },
        {
            "comment": "This code creates directories and files for an experiment, writes metadata to a JSON file, reads information from txt files, prints the content of each file, and performs testing if not running training.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":140-164",
            "content": "        os.makedirs(experiment_path, exist_ok=True)\n    with open(os.path.join(experiment_path, \"meta_info_{}.json\".format(time_string)), 'w') as f:\n        json.dump(meta_info, f)\n    all_substeps = os.path.join(solution_path, \"substeps.txt\")\n    with open(all_substeps, 'r') as f:\n        substeps = f.readlines()\n    print(\"all substeps:\\n {}\".format(\"\".join(substeps)))\n    substep_types = os.path.join(solution_path, \"substep_types.txt\")\n    with open(substep_types, 'r') as f:\n        substep_types = f.readlines()\n    print(\"all substep types:\\n {}\".format(\"\".join(substep_types)))\n    action_spaces = os.path.join(solution_path, \"action_spaces.txt\")\n    with open(action_spaces, 'r') as f:\n        action_spaces = f.readlines()\n    print(\"all action spaces:\\n {}\".format(\"\".join(action_spaces)))\n    if not run_training:\n        test_env(solution_path, time_string, substeps, action_spaces, meta_info, randomize=randomize, obj_id=obj_id, gui=gui, move_robot=move_robot)\n        exit()\n    all_rgbs = []\n    for "
        },
        {
            "comment": "This code snippet iterates through substeps, skipping certain ones based on provided conditions. It trims unnecessary whitespaces from substep names and prints the executing substep before checking if it's a \"primitive\" type and if motion planning should be used. If so, it creates directories for primitive state saves.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":164-183",
            "content": "step_idx, (substep, substep_type, action_space) in enumerate(zip(substeps, substep_types, action_spaces)):\n        if (skip is not None) and (step_idx < len(skip)) and int(skip[step_idx]):\n            print(\"skip substep: \", substep)\n            continue\n        if only_learn_substep is not None and step_idx != only_learn_substep:\n            print(\"skip substep: \", substep)\n            continue\n        substep = substep.lstrip().rstrip()\n        substep_type = substep_type.lstrip().rstrip()\n        action_space = action_space.lstrip().rstrip()\n        print(\"executing for substep:\\n {} {}\".format(substep, substep_type))\n        if substep_type == \"primitive\" and use_motion_planning:\n            save_path = os.path.join(solution_path, \"primitive_states\", time_string, substep.replace(\" \", \"_\"))\n            if not os.path.exists(save_path):\n                os.makedirs(save_path, exist_ok=True)\n            all_files = os.listdir(save_path)\n            all_pkl_files = [f for f in all_files if f.endswith(\".pkl\")]"
        },
        {
            "comment": "The code checks if the \"execute.gif\" file exists at the specified save_path and if the simulation should be resumed. If it already exists, it loads the last restore state from a pickle file, skips execution for this substep, and extends the list of all rgbs with frames from the existing gif file. If not, it calls the execute_primitive function to perform the task, saving the final state as a pickle file. It also saves the rgb frames into a gif file named \"execute\" at the save path. For reward substep type, it sets the save path to include the training algorithm and current time. If there is a specified reward_learning_save_path, it proceeds further with the code execution.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":184-200",
            "content": "            gif_path = os.path.join(save_path, \"execute.gif\")\n            if os.path.exists(gif_path) and resume:\n                print(\"final state already exists, skip {}\".format(substep))\n                sorted_pkl_files = sorted(all_pkl_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n                last_restore_state_file = os.path.join(save_path, sorted_pkl_files[-1])\n                all_rgbs.extend(load_gif(gif_path))\n            else:\n                rgbs, states = execute_primitive(task_config_path, solution_path, substep, last_restore_state_file, save_path, \n                                                 gui=gui, randomize=randomize, obj_id=obj_id,)\n                last_restore_state_file = states[-1]\n                all_rgbs.extend(rgbs)\n                save_numpy_as_gif(np.array(rgbs), \"{}/{}.gif\".format(save_path, \"execute\"))\n        if substep_type == \"reward\":\n            save_path = os.path.join(solution_path, training_algo, time_string, substep.replace(\" \", \"_\"))\n            if reward_learning_save_path is not None:"
        },
        {
            "comment": "The code checks if the final state already exists and skips if it does, otherwise it runs an RL algorithm to find the best model path, rgbs, and state files. It also creates a gif file if it doesn't exist and resumes from the last saved state if instructed.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":201-219",
            "content": "                save_path = reward_learning_save_path\n            if not os.path.exists(save_path):\n                os.makedirs(save_path)\n            all_files = os.listdir(save_path)\n            pkl_dir = os.path.join(save_path, \"best_state\")\n            gif_path = os.path.join(save_path, \"execute.gif\")\n            if os.path.exists(gif_path) and resume:\n                all_files = os.listdir(pkl_dir)\n                all_pkl_files = [f for f in all_files if f.endswith(\".pkl\")]\n                sorted_pkl_files = sorted(all_pkl_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n                print(\"final state already exists, skip {}\".format(substep))\n                last_restore_state_file = os.path.join(pkl_dir, sorted_pkl_files[-1])\n                all_rgbs.extend(load_gif(gif_path))\n            else:\n                algo = training_algo.split(\"_\")[1]\n                task_name = substep.replace(\" \", \"_\")\n                best_model_path, rgbs, state_files = run_RL(task_config_path, solution_path, task_name, "
        },
        {
            "comment": "This code is initializing an object, likely a robot or AI agent, with specific parameters and arguments. It's setting the last restore state file, saving path, action space, algorithm, rendering mode, number of timesteps, randomization, usage of GPT-based features, distractor usage, etc. Finally, it extends the list of all RGB values with current RGB values.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":220-231",
            "content": "                                                            last_restore_state_file, save_path=save_path, action_space=action_space,\n                                                            algo=algo, render=gui, timesteps_total=1000000, \n                                                            randomize=randomize,\n                                                            use_bard=use_bard,\n                                                            obj_id=obj_id,\n                                                            use_gpt_size=use_gpt_size,\n                                                            use_gpt_joint_angle=use_gpt_joint_angle,\n                                                            use_gpt_spatial_relationship=use_gpt_spatial_relationship,\n                                                            use_distractor=use_distractor,\n                                                            )\n                last_restore_state_file = state_files[-1]\n                all_rgbs.extend(rgbs)"
        },
        {
            "comment": "This code appears to be part of a Python script for executing a task configuration and saving the final results as a GIF. It uses the RoboGen library, handles time-stamping, and allows for resuming from a previous state if needed. The code also utilizes argument parsing through argparse and includes options for task configuration path, training algorithm, resume flag, time string, gui mode, and randomization of object rotations.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":232-254",
            "content": "                save_numpy_as_gif(np.array(rgbs), \"{}/{}.gif\".format(save_path, \"execute\"))\n            if only_learn_substep is not None:\n                return\n        all_last_state_files.append(str(last_restore_state_file))\n        with open(os.path.join(experiment_path, \"all_last_state_files_{}.txt\".format(time_string)), 'w') as f:\n            f.write(\"\\n\".join(all_last_state_files))\n    # save the final gif\n    save_path = os.path.join(solution_path)\n    save_numpy_as_gif(np.array(all_rgbs), \"{}/{}-{}.gif\".format(save_path, \"all\", time_string))\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--task_config_path', type=str, default=None)\n    parser.add_argument('--training_algo', type=str, default=\"RL_sac\")\n    parser.add_argument('--resume', type=int, default=0)\n    parser.add_argument('--time_string', type=str, default=None)\n    parser.add_argument('--gui', type=int, default=0) \n    parser.add_argument('--randomize', type=int, default=0) # whether to randomize roation of objects in the scene."
        },
        {
            "comment": "The code above defines command-line arguments using the argparse module in Python. These arguments control various aspects of the program's behavior, including which object to use, whether to utilize Bard or GPT features, and whether to run training or just build the scene. The defaults are provided for each argument, allowing users to override them if needed.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":255-264",
            "content": "    parser.add_argument('--obj_id', type=int, default=0) # which object from the list of possible objects to use.\n    parser.add_argument('--use_bard', type=int, default=1) # whether to use bard filtered objects.\n    parser.add_argument('--use_gpt_size', type=int, default=1) # whether to use size outputted from gpt.\n    parser.add_argument('--use_gpt_spatial_relationship', type=int, default=1) # whether to use gpt spatial relationship.\n    parser.add_argument('--use_gpt_joint_angle', type=int, default=1) # whether to use initial joint angle output from gpt.\n    parser.add_argument('--run_training', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--use_motion_planning', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--use_distractor', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--skip', nargs=\"+\", default=[]) # if to train or just to build the scene.\n    parser.add_argument('--move_robot', type=int, default=0) # if to train or just to build the scene."
        },
        {
            "comment": "The code snippet is part of a Python script that uses the argparse module to parse command-line arguments. These arguments determine which features to run or skip in the program's execution, such as learning for a substep, saving learning results, and restoring from a specific state. The script then calls the execute function with these arguments, controlling its behavior based on user input.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":265-282",
            "content": "    parser.add_argument('--only_learn_substep', type=int, default=None) # if to run learning for a substep.\n    parser.add_argument('--reward_learning_save_path', type=str, default=None) # where to store the learning result of RL training. \n    parser.add_argument('--last_restore_state_file', type=str, default=None) # whether to start from a specific state.\n    args = parser.parse_args()\n    task_config_path = args.task_config_path\n    execute(task_config_path, resume=args.resume, training_algo=args.training_algo, time_string=args.time_string, \n            gui=args.gui, \n            randomize=args.randomize,\n            use_bard=args.use_bard,\n            use_gpt_size=args.use_gpt_size,\n            use_gpt_joint_angle=args.use_gpt_joint_angle,\n            use_gpt_spatial_relationship=args.use_gpt_spatial_relationship,\n            run_training=args.run_training,\n            obj_id=args.obj_id,\n            use_motion_planning=args.use_motion_planning,\n            use_distractor=args.use_distractor,\n            skip=args.skip,"
        },
        {
            "comment": "This code snippet is creating an object of some class (possibly RoboGen) with four parameters: move_robot, only_learn_substep, reward_learning_save_path, and last_restore_state_file. These parameters are taken from the args dictionary in Python's argparse module. The function is likely used to initialize or configure an instance of this class based on user input.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute.py\":283-287",
            "content": "            move_robot=args.move_robot,\n            only_learn_substep=args.only_learn_substep,\n            reward_learning_save_path=args.reward_learning_save_path,\n            last_restore_state_file=args.last_restore_state_file\n    )"
        }
    ]
}