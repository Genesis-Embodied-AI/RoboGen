{
    "summary": "This code allows robots to complete household tasks by assigning actions and rewards, dividing manipulation tasks, using primitive grasping, and preventing repetitions with proximity/angle differences. It also calculates task rewards, defines grasping/releasing functions, and suggests action spaces in robotics environments using Gym.",
    "details": [
        {
            "comment": "The code provides a description of a task where a robotic arm needs to learn household object manipulation skills in a simulator. The user is asked to decompose the given tasks into executable sub-steps, assign primitive actions or reward functions for each substep, and write functions to check if each substep has been completed successfully.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":0-18",
            "content": "import copy\nfrom gpt_4.query import query\nimport os\nuser_contents = [\n\"\"\"\nA robotic arm is trying to solve some household object manipulation tasks to learn corresponding skills in a simulator.\nWe will provide with you the task description, the initial scene configurations of the task, which contains the objects in the task and certain information about them. \nYour goal is to decompose the task into executable sub-steps for the robot, and for each substep, you should either call a primitive action that the robot can execute, or design a reward function for the robot to learn, to complete the substep. \nFor each substep, you should also write a function that checks whether the substep has been successfully completed. \nCommon substeps include moving towards a location, grasping an object, and interacting with the joint of an articulated object.\nAn example task:\nTask Name: Set oven temperature\nDescription: The robotic arm will turn the knob of an oven to set a desired temperature.\nInitial config:\n```yaml"
        },
        {
            "comment": "This code defines the properties of an object, likely for a robotics task. The \"oven\" is a freestanding object with its URDF path specified and a size of 0.85. Its location is in the world coordinate system when not on a table. The reward primitive may require access to joint values or link positions within the articulation tree defined for the oven.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":19-43",
            "content": "-   use_table: false\n-   center: (1, 0, 0) # when an object is not on the table, the center specifies its location in the world coordinate. \n    lang: a freestanding oven \n    name: oven\n    on_table: false\n    path: oven.urdf\n    size: 0.85\n    type: urdf\n```\nI will also give you the articulation tree and semantics file of the articulated object in the task. Such information will be useful for writing the reward function/the primitive actions, for example, when the reward requires accessing the joint value of a joint in the articulated object, or the position of a link in the articulated object, or when the primitive needs to access a name of the object.\n```Oven articulation tree:\nlinks: \nbase\nlink_0\nlink_1\nlink_2\nlink_3\nlink_4\njoints: \njoint_name: joint_0 joint_type: continuous parent_link: link_4 child_link: link_0\njoint_name: joint_1 joint_type: continuous parent_link: link_4 child_link: link_1\njoint_name: joint_2 joint_type: continuous parent_link: link_4 child_link: link_2\njoint_name: joint_3 joint_type: continuous parent_link: link_4 child_link: link_3"
        },
        {
            "comment": "This code defines a joint named \"joint_4\" with type \"fixed\", connecting the \"base\" parent link to the \"link_4\" child link. The articulated object's semantics outline four hinge knob links (link_0 to link_3) and one heavy oven_body link (link_4). The objective is for the robot to learn to manipulate the knob (link_0) to control the oven temperature by actuating joint_0, a continuous joint connecting link_0.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":44-65",
            "content": "joint_name: joint_4 joint_type: fixed parent_link: base child_link: link_4\n```\n```Oven semantics\nlink_0 hinge knob\nlink_1 hinge knob\nlink_2 hinge knob\nlink_3 hinge knob\nlink_4 heavy oven_body\n```\nI will also give you the links and joints of the articulated object that will be used for completing the task:\nLinks:\nlink_0: We know from the semantics that link_0 is a hinge knob. It is assumed to be the knob that controls the temperature of the oven. The robot needs to actuate this knob to set the temperature of the oven.\nJoints:\njoint_0: from the articulation tree, joint_0 connects link_0 and is a continuous joint. Therefore, the robot needs to actuate joint_0 to turn link_0, which is the knob.\nFor each substep, you should decide whether the substep can be achieved by using the provided list of primitives. If not, you should then write a reward function for the robot to learn to perform this substep. \nIf you choose to write a reward function for the substep, you should also specify the action space of the robot when learning this reward function. "
        },
        {
            "comment": "The code defines two action spaces: \"delta-translation\" for local movements and \"normalized-direct-translation\" for target location. It suggests adding a condition to check if each substep is successful, and lists three robot primitives: grasp_object, grasp_object_link, and release_grasp. All primitives return a tuple. The robot has a suction gripper for grasping objects or links on objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":66-73",
            "content": "There are 2 options for the action space: \"delta-translation\", where the action is the delta translation of the robot end-effector, suited for local movements; and \"normalized-direct-translation\", where the action specifies the target location the robot should move to, suited for moving to a target location.\nFor each substep, you should also write a condition that checks whether the substep has been successfully completed.\nHere is a list of primitives the robot can do. The robot is equipped with a suction gripper, which makes it easy for the robot to grasp an object or a link on an object. \ngrasp_object(self, object_name): the robot arm will grasp the object specified by the argument object name.\ngrasp_object_link(self, object_name, link_name): some object like an articulated object is composed of multiple links. The robot will grasp a link with link_name on the object with object_name. \nrelease_grasp(self): the robot will release the grasped object.\nNote that all primitives will return a tu"
        },
        {
            "comment": "This function is designed to accept a list of RGB images and the final state of an execution process. It must be called using the specified format. The code provides helper functions like get_position, get_orientation, get_joint_state, get_joint_limit, get_link_state, and get_eef_pos for designing reward functions or success conditions.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":73-84",
            "content": "ple (rgbs, final_state) which represents the rgb images of the execution process and the final state of the execution process. \nYou should always call the primitive in the following format:\nrgbs, final_state = some_primitive_function(self, arg1, ..., argn)\nHere is a list of helper functions that you can use for designing the reward function or the success condition:\nget_position(self, object_name): get the position of center of mass of object with object_name.\nget_orientation(self, object_name): get the orientation of an object with object_name.\nget_joint_state(self, object_name, joint_name): get the joint angle value of a joint in an object.\nget_joint_limit(self, object_name, joint_name): get the lower and upper joint angle limit of a joint in an object, returned as a 2-element tuple.\nget_link_state(self, object_name, link_name): get the position of the center of mass of the link of an object.\nget_eef_pos(self): returns the position, orientation of the robot end-effector as a list.\nget_bounding"
        },
        {
            "comment": "The code provides various utility functions for manipulating objects, such as obtaining the bounding box of an object or its link, checking if a position is within a bounding box, and determining if an object or a specific link of an object is grasped. The functions also allow retrieving the initial position, orientation, and joint angle of an object at the beginning of the task.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":84-91",
            "content": "_box(self, object_name): get the axis-aligned bounding box of an object. It returns the min and max xyz coordinate of the bounding box.\nget_bounding_box_link(self, object_name, link_name): get the axis-aligned bounding box of the link of an object. It returns the min and max xyz coordinate of the bounding box.\nin_bbox(self, pos, bbox_min, bbox_max): check if pos is within the bounding box with the lowest corner at bbox_min and the highest corner at bbox_max. \ncheck_grasped(self, object_name, link_name): return true if an object or a link of the object is grasped. link_name can be none, in which case it will check whether the object is grasped.\nget_initial_pos_orient(self, obj): get the initial position and orientation of an object at the beginning of the task.\nget_initial_joint_angle(self, obj_name, joint_name): get the initial joint angle of an object at the beginning of the task.\nYou can assume that for objects, the lower joint limit corresponds to their natural state, e.g., a box is closed with the lid joint being 0, and a lever is unpushed when the joint angle is 0."
        },
        {
            "comment": "This code decomposes the task \"Set oven temperature\" into two substeps and provides primitives for each substep. Substep 1 is \"grasp the temperature knob,\" with a primitive that uses grasp_object_link function to achieve it. Substep 2 is \"turn the temperature knob to set a desired temperature,\" which has a reward function _compute_reward defining the reward for this action, encouraging the end-effector to stay near the knob while turning it. The desired temperature is assumed to be one third of the joint angle range.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":93-114",
            "content": "For the above task \"Set oven temperature\", it can be decomposed into the following substeps, primitives, and reward functions:\nsubstep 1: grasp the temperature knob\n```primitive\n\trgbs, final_state = grasp_object_link(self, \"oven\", \"link_0\") \n    success = check_grasped(self, \"oven\", \"link_0\")\n```\nsubstep 2: turn the temperature knob to set a desired temperature\n```reward\ndef _compute_reward(self):\n    # This reward encourages the end-effector to stay near the knob to grasp it.\n    eef_pos = get_eef_pos(self)[0]\n    knob_pos = get_link_state(self, \"oven\", \"link_0\")\n    reward_near = -np.linalg.norm(eef_pos - knob_pos)\n    joint_angle = get_joint_state(self, \"oven\", \"joint_0\") \n    joint_limit_low, joint_limit_high = get_joint_limit(self, \"oven\", \"joint_0\")\n    desired_temperature = joint_limit_low + (joint_limit_high - joint_limit_low)  / 3 # We assume the target desired temperature is one third of the joint angle. It can also be 1/3, or other values between joint_limit_low and joint_limit_high. \n    #"
        },
        {
            "comment": "The code calculates the reward for a robotic arm reaching a desired temperature by comparing the current joint angle to the desired temperature and subtracting them. The reward is then multiplied by a factor of 5 before being added to another reward variable. A success condition is also set if the difference between the two angles is less than a certain threshold. Finally, the reward and success are returned.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":114-153",
            "content": " The reward is the negative distance between the current joint angle and the joint angle of the desired temperature.\n    diff = np.abs(joint_angle - desired_temperature)\n    reward_joint =  -diff\n    reward = reward_near + 5 * reward_joint\n    success = diff < 0.1 * (joint_limit_high - joint_limit_low)\n    return reward, success\n```\n```action space\ndelta-translation\n```\nI will give some more examples of decomposing the task. Reply yes if you understand the goal.\n\"\"\",\n\"\"\"\nAnother example:\nTask Name: Fetch item from refrigerator\nDescription: The robotic arm will open a refrigerator door reach inside to grab an item, place it on the table, and then close the door\nInitial config:\n```yaml\n-   use_table: true \n-   center: (1.2, 0, 0)\n    lang: a common two-door refrigerator\n    name: Refrigerator\n    on_table: false \n    path: refrigerator.urdf\n    size: 1.8\n    type: urdf\n-   center: (1.2, 0, 0.5) \n    lang: a can of soda\n    name: Item\n    on_table: false \n    path: soda_can.obj\n    size: 0.2\n    type: mesh\n```\n```Refrigerator articulation tree"
        },
        {
            "comment": "This code segment describes a robot task involving a refrigerator. The robot needs to reach for an item inside the refrigerator by grasping and opening the door. Substep 1 involves grasping the refrigerator door using the \"grasp_object_link\" primitive, while substep 2 encourages staying near the door to grasp it with the reward function \"_compute_reward\". The goal is to open the door to reach for the item inside the refrigerator.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":154-188",
            "content": "links: \nbase\nlink_0\nlink_1\nlink_2\njoints: \njoint_name: joint_0 joint_type: fixed parent_link: base child_link: link_0\njoint_name: joint_1 joint_type: revolute parent_link: link_0 child_link: link_1\njoint_name: joint_2 joint_type: revolute parent_link: link_0 child_link: link_2\n```\n```Refrigerator semantics\nlink_0 heavy refrigerator_body\nlink_1 hinge door\nlink_2 hinge door\n```\nLinks:\nlink_1: This link is one of the refrigerator doors, which the robot neesd to reach for the item inside.\nJoints:\njoint_1: This joint connects link_1, representing one of the doors. The robot needs to actuate this joint to open the door, reach for the item, and close the door.\nThis task can be decomposed as follows:\nsubstep 1: grasp the refrigerator door\n```primitive\n    rgbs, final_state = grasp_object_link(self, \"Refrigerator\", \"link_1\")  \n    success = check_grasped(self, \"Refrigerator\", \"link_1\")\n```\nsubstep 2: open the refrigerator door\n```reward\ndef _compute_reward(self):\n    # this reward encourages the end-effector to stay near door to grasp it."
        },
        {
            "comment": "This code calculates the reward and success for opening a door. It first gets the EEF position, door position, and joint angle of the door. Then it computes the negative distance between the EEF position and door position as 'reward_near', and the difference between the current joint angle and upper limit as 'reward_joint'. The reward is the sum of these two values. If the difference in joint angle is less than 0.35 times the range of joint limits, the success is true. This code assumes that the robot has already grasped the door and only needs local movements to open it.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":189-209",
            "content": "    eef_pos = get_eef_pos(self)[0]\n    door_pos = get_link_state(self, \"Refrigerator\", \"link_1\")\n    reward_near = -np.linalg.norm(eef_pos - door_pos)\n    # Get the joint state of the door. We know from the semantics and the articulation tree that joint_1 connects link_1 and is the joint that controls the rotation of the door.\n    joint_angle = get_joint_state(self, \"Refrigerator\", \"joint_1\") \n    # The reward is the negative distance between the current joint angle and the joint angle when the door is fully open (upper limit).\n    joint_limit_low, joint_limit_high = get_joint_limit(self, \"Refrigerator\", \"joint_1\")\n    diff = np.abs(joint_angle - joint_limit_high)\n    reward_joint =  -diff\n    reward = reward_near + 5 * reward_joint\n    success = diff < 0.35 * (joint_limit_high - joint_limit_low) # for opening, we think 65 percent is enough\n    return reward, success\n```\n```action space\ndelta-translation\n```\nIn the last substep the robot already grasps the door, thus only local movements are needed to open it. "
        },
        {
            "comment": "This code is related to a robotics task where the goal is to grasp an item, move it out of the refrigerator, and place it on the table. It consists of four substeps: 1) approach the refrigerator, 2) open the door, 3) grasp the item, and 4) move the item out of the refrigerator. The code calculates rewards to encourage the robot to stay near the item, grasp it, and place it on the table rather than moving it randomly out of the refrigerator. It uses position data from the end-effector (robot's hand), the item, and the table in the simulation.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":211-233",
            "content": "substep 3: grasp the item\n```primitive\n    rgbs, final_state = grasp_object(self, \"Item\")\n    success = check_grasped(self, \"Item\")\n```\nsubstep 4: move the item out of the refrigerator\n```reward\ndef _compute_reward(self):\n    # Get the current item position\n    item_pos = get_position(self, \"Item\")\n    # The first reward encourages the end-effector to stay near the item\n    eef_pos = get_eef_pos(self)[0]\n    reward_near = -np.linalg.norm(eef_pos - item_pos)\n    # The reward is to encourage the robot to grasp the item and move the item to be on the table. \n    # The goal is not to just move the soda can to be at a random location out of the refrigerator. Instead, we need to place it somewhere on the table. \n    # This is important for moving an object out of a container style of task.\n    table_bbox_low, table_bbox_high = get_bounding_box(self, \"init_table\") # the table is referred to as \"init_table\" in the simulator. \n    table_bbox_range = table_bbox_high - table_bbox_low\n    # target location is to put the item at a random location on the table"
        },
        {
            "comment": "This code calculates the reward and success for reaching a target location (substep 1) by generating a random number in [0, 1] to adjust coordinates of the target. It also handles grasping the refrigerator door again (substep 5), encouraging the end-effector to stay near the door during closing the refrigerator door (substep 6).",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":234-262",
            "content": "    target_location = np.zeros(3)\n    target_location[0] = table_bbox_low[0] + 0.2 * table_bbox_range[0] # 0.2 is a random chosen number, any number in [0, 1] should work\n    target_location[1] = table_bbox_low[1] + 0.3 * table_bbox_range[1] # 0.3 is a random chosen number, any number in [0, 1] should work\n    target_location[2] = table_bbox_high[2] + 0.05 # target height is slightly above the table\n    diff = np.linalg.norm(item_pos - target_location)\n    reward_distance = -diff\n    reward = reward_near + 5 * reward_distance\n    success = diff < 0.06\n    return reward, success\n```\n```action space\nnormalized-direct-translation\n```\nSince this substep requires moving the item to a target location, we use the normalized-direct-translation.\nsubstep 5: grasp the refrigerator door again\n```primitive\n    rgbs, final_state = grasp_object_link(self, \"Refrigerator\", \"link_1\")\n    success = check_grasped(self, \"Refrigerator\", \"link_1\") \n```\nsubstep 6: close the refrigerator door\n```reward\ndef _compute_reward(self):\n    # this reward encourages the end-effector to stay near door"
        },
        {
            "comment": "The code calculates a reward for the robot to encourage it to close a door by considering both the distance between the end-effector position and the door's position, as well as the joint angle of the door. The closer the door is to being closed and the lower the joint angle is, the higher the reward will be. A success threshold is also defined to check if the robot has successfully closed the door by verifying that the difference between the joint angle and its limit is below a certain threshold (10% of the range between the joint limits). The action space is delta-translation, indicating the robotic arm will move in small increments towards the target position.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":263-293",
            "content": "    eef_pos = get_eef_pos(self)[0]\n    door_pos = get_link_state(self, \"Refrigerator\", \"link_1\")\n    reward_near = -np.linalg.norm(eef_pos - door_pos)\n    # Get the joint state of the door. \n    joint_angle = get_joint_state(self, \"Refrigerator\", \"joint_1\") \n    # The reward encourages the robot to make joint angle of the door to be the lower limit to clost it.\n    joint_limit_low, joint_limit_high = get_joint_limit(self, \"Refrigerator\", \"joint_1\")\n    diff = np.abs(joint_limit_low - joint_angle)\n    reward_joint =  -diff\n    reward = reward_near + 5 * reward_joint\n    success = diff < 0.1 * (joint_limit_high - joint_limit_low) # for closing, we think 10 percent is enough     \n    return reward, success\n```\n```action space\ndelta-translation\n```\nI will provide more examples in the following messages. Please reply yes if you understand the goal.\n\"\"\",\n\"\"\"\nHere is another example:\nTask Name:  Put a toy car inside a box\nDescription: The robotic arm will open a box, grasp the toy car and put it inside the box.\nInitial config:"
        },
        {
            "comment": "This code defines a box with articulation tree and semantics, consisting of links link_0, link_1, and link_2. Link_0 and link_1 are both lids that need to be opened for the box to be fully open, while joint_0 is a hinge joint connecting link_0 and requiring actuation to open it.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":294-333",
            "content": "```yaml\n-  use_table: True \n-   center: (0.2, 0.3, 0)\n    on_table: True\n    lang: a box\n    name: box\n    size: 0.25\n    type: urdf\n-   center: (0.1, 0.6, 0)\n    on_table: True\n    lang: a toy car\n    name: toy_car\n    size: 0.1\n    type: mesh\n```\n```box articulation tree\nlinks: \nbase\nlink_0\nlink_1\nlink_2\njoints: \njoint_name: joint_0 joint_type: revolute parent_link: link_2 child_link: link_0\njoint_name: joint_1 joint_type: revolute parent_link: link_2 child_link: link_1\njoint_name: joint_2 joint_type: fixed parent_link: base child_link: link_2\n```\n```box semantics\nlink_0 hinge rotation_lid\nlink_1 hinge rotation_lid\nlink_2 free box_body\n```\nLinks:\nlink_0: To fully open the box, the robot needs to open both box lids. We know from the semantics that link_0 is one of the lids.\nlink_1: To fully open the box, the robot needs to open both box lids. We know from the semantics that link_1 is another lid.\nJoints:\njoint_0: from the articulation tree, joint_0 connects link_0 and is a hinge joint. Thus, the robot needs to actuate joint_0 to open link_0, which is the lid of the box."
        },
        {
            "comment": "This code decomposes a task into two substeps: grasping the first lid of the box and then opening it. The reward function encourages the end-effector to stay near the lid to grasp it, and calculates the joint state of the first lid.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":334-355",
            "content": "joint_1: from the articulation tree, joint_1 connects link_1 and is a hinge joint. Thus, the robot needs to actuate joint_1 to open link_1, which is the lid of the box.\nThis task can be decomposed as follows:\nsubstep 1: grasp the first lid of the box\n```primitive\n\t# The semantics shows that link_0 and link_1 are the lid links. \n\trgbs, final_state = grasp_object_link(self, \"box\", \"link_0\")  \n    success = check_grasped(self, \"box\", \"link_0\")\n```\nsubstep 2: open the first lid of the box\n```reward\ndef _compute_reward(self):\n    # This reward encourages the end-effector to stay near the lid to grasp it.\n    eef_pos = get_eef_pos(self)[0]\n    lid_pos = get_link_state(self, \"box\", \"link_0\")\n    reward_near = -np.linalg.norm(eef_pos - lid_pos)\n    # Get the joint state of the first lid. The semantics and the articulation tree show that joint_0 connects link_0 and is the joint that controls the rotation of the first lid link_0.\n    joint_angle = get_joint_state(self, \"box\", \"joint_0\") \n    # The reward is the "
        },
        {
            "comment": "The code calculates the negative distance between the current joint angle and the upper limit (when the lid is fully open) to compute a reward for opening the second lid of the box. It also checks if the difference is less than 0.35 times the range of the joint limits, indicating success in opening the lid. Additionally, it encourages the end-effector to stay near the lid for grasping purposes.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":355-385",
            "content": "negative distance between the current joint angle and the joint angle when the lid is fully open (upper limit).\n    joint_limit_low, joint_limit_high = get_joint_limit(self, \"box\", \"joint_0\")\n    diff = np.abs(joint_angle - joint_limit_high)\n    reward_joint =  -diff\n    reward = reward_near + 5 * reward_joint\n    success = diff < 0.35 * (joint_limit_high - joint_limit_low)\n    return reward, success\n```\n```action space\ndelta-translation\n```\nsubstep 3: grasp the second lid of the box\n```primitive\n\t# We know from the semantics that link_0 and link_1 are the lid links. \n\trgbs, final_state = grasp_object_link(self, \"box\", \"link_1\")  \n    success = check_grasped(self, \"box\", \"link_1\")\n```\nsubstep 4: open the second lid of the box\n```reward\ndef _compute_reward(self):\n    # This reward encourages the end-effector to stay near the lid to grasp it.\n    eef_pos = get_eef_pos(self)[0]\n    lid_pos = get_link_state(self, \"box\", \"link_1\")\n    reward_near = -np.linalg.norm(eef_pos - lid_pos)\n    # Get the joint state of the second lid. "
        },
        {
            "comment": "This code calculates the reward for a robot manipulation task involving a box and a toy car. The reward is determined by the distance between the current joint angle of the box and its upper limit, as well as the proximity of the robot's end-effector to the toy car. This code also checks if the lid of the box is fully open and calculates the success of grasping the toy car and placing it inside the box.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":386-415",
            "content": "    joint_angle = get_joint_state(self, \"box\", \"joint_1\") \n    # The reward is the negative distance between the current joint angle and the joint angle when the lid is fully open (upper limit).\n    joint_limit_low, joint_limit_high = get_joint_limit(self, \"box\", \"joint_1\")\n    diff = np.abs(joint_angle - joint_limit_high)\n    reward_joint =  -diff\n    reward = reward_near + 5 * reward_joint\n    success = diff < 0.35 * (joint_limit_high - joint_limit_low)\n    return reward, success\n```\n```action space\ndelta-translation\n```\nsubstep 5: grasp the toy car\n```primitive\n\trgbs, final_state = grasp_object(self, \"toy_car\")\n    success = check_grasped(self, \"toy_car\")\n```\nsubstep 6: put the toy car into the box\n```reward\ndef _compute_reward(self):\n    # This reward encourages the end-effector to stay near the car to grasp it.\n    car_position = get_position(self, \"toy_car\")\n    eef_pos = get_eef_pos(self)[0]\n    reward_near = -np.linalg.norm(eef_pos - car_position)\n    # main reward is 1 if the car is inside the box. From the semantics we know that link2 is the box body"
        },
        {
            "comment": "The code calculates two rewards: reward_in and reward_reaching. It checks if the car is inside the box bounding box (success) and combines these rewards to form the final reward. The action space used for this task is normalized-direct-translation, as it involves moving an item to a target location.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":416-438",
            "content": "    box_bbox_low, box_bbox_high = get_bounding_box_link(self, \"box\", \"link_2\")\n    reward_in = int(in_bbox(self, car_position, box_bbox_low, box_bbox_high))\n    # another reward is to encourage the robot to move the car to be near the box\n    reward_reaching = - np.linalg.norm(car_position - (box_bbox_low + box_bbox_high) / 2)\n    # The task is considered to be successful if the car is inside the box bounding box\n    success = reward_in\n    # We give more weight to reward_in, which is the major goal of the task.\n    reward = 5 * reward_in + reward_reaching + reward_near\n    return reward, success\n```\n```action space\nnormalized-direct-translation\n```\nSince this substep requires moving the item to a target location, we use the normalized-direct-translation.\nPlease decompose the following task into substeps. For each substep, write a primitive/a reward function, write the success checking function, and the action space if the reward is used. \nThe primitives you can call:\ngrasp_object(self, object_name): the robot arm will grasp the object specified by the argument object name."
        },
        {
            "comment": "This code defines two primitive functions: \"grasp_object_link\" and \"release_grasp\". These functions allow a robot to grasp an object link and then release the grasped object. The primitives return RGB images of the execution process and the final state. The provided API includes functions for obtaining position, orientation, joint angle values, and joint angle limits for object manipulation.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":439-449",
            "content": "grasp_object_link(self, object_name, link_name): some object like an articulated object is composed of multiple links. The robot will grasp a link with link_name on the object with object_name. \nrelease_grasp(self): the robot will release the grasped object.\nNote that all primitives will return a tuple (rgbs, final_state) which represents the rgb images of the execution process and the final state of the execution process. \nYou should always call the primitive in the following format:\nrgbs, final_state = some_primitive_function(self, arg1, ..., argn)\nThe APIs you can use for writing the reward function/success checking function:\nget_position(self, object_name): get the position of center of mass of object with object_name.\nget_orientation(self, object_name): get the orientation of an object with object_name.\nget_joint_state(self, object_name, joint_name): get the joint angle value of a joint in an object.\nget_joint_limit(self, object_name, joint_name): get the lower and upper joint angle limit of a joint in an object, returned as a 2-element tuple."
        },
        {
            "comment": "This code contains various methods for object manipulation, such as getting the position of an object's center of mass, obtaining the end-effector position and orientation, retrieving bounding box information for objects or their links, checking if a given position is within a bounding box, determining if an object or link is grasped, and retrieving initial position and orientation at the start of a task.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":450-457",
            "content": "get_link_state(self, object_name, link_name): get the position of the center of mass of the link of an object.\nget_eef_pos(self): returns the position, orientation of the robot end-effector as a list.\nget_bounding_box(self, object_name): get the axis-aligned bounding box of an object. It returns the min and max xyz coordinate of the bounding box.\nget_bounding_box_link(self, object_name, link_name): get the axis-aligned bounding box of the link of an object. It returns the min and max xyz coordinate of the bounding box.\nin_bbox(self, pos, bbox_min, bbox_max): check if pos is within the bounding box with the lowest corner at bbox_min and the highest corner at bbox_max. \ncheck_grasped(self, object_name, link_name): return true if an object or a link of the object is grasped. link_name can be none, in which case it will check whether the object is grasped.\nget_initial_pos_orient(self, obj): get the initial position and orientation of an object at the beginning of the task.\nget_initial_joint_angle"
        },
        {
            "comment": "This code is part of a robotics learning environment, where it defines a class that retrieves the initial joint angle of an object at the beginning of a task. It suggests using different action spaces for learning with rewards depending on the type of movement being made. The code also assumes that objects have natural states corresponding to their lower joint limits.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":457-488",
            "content": "(self, obj_name, joint_name): get the initial joint angle of an object at the beginning of the task.\nThe action space you can use for learning with the reward: delta-translation is better suited for small movements, and normalized-direct-translation is better suited for directly specifying the target location of the robot end-effector. \nYou can assume that for objects, the lower joint limit corresponds to their natural state, e.g., a box is closed with the lid joint being 0, and a lever is unpushed when the joint angle is 0.\n\"\"\"\n]\nassistant_contents = [\n\"\"\"\nYes, I understand the goal. Please proceed with the next example.\n\"\"\",\n\"\"\"\nYes, I understand the goal. Please proceed with the next example.\n\"\"\"\n]\nreward_file_header1 = \"\"\"\nfrom manipulation.sim import SimpleEnv\nimport numpy as np\nfrom manipulation.gpt_reward_api import *\nfrom manipulation.gpt_primitive_api import *\nimport gym\nclass {}(SimpleEnv):\n\"\"\"\nreward_file_header2 = \"\"\"\n    def __init__(self, task_name, *args, **kwargs):\n        super().__init__(*args, **kwargs)"
        },
        {
            "comment": "This code is generating a reward or primitive function for a robotics task. It uses Gym, a reinforcement learning library, to define and register an environment with the specified task name. The code creates classes for both reward and primitive functions, and includes initialization and execution methods. The `decompose_and_generate_reward_or_primitive` function takes various inputs such as task description, initial configuration, articulation tree, semantics, involved links, joints, object ID, and more to generate the appropriate environment for the robotics task.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":489-534",
            "content": "        self.task_name = task_name\n        self.detected_position = {}\n\"\"\"\nreward_file_end = \"\"\"\ngym.register(\n    id='gym-{}-v0',\n    entry_point={},\n)\n\"\"\"\nprimitive_file_header1 = \"\"\"\nfrom manipulation.sim import SimpleEnv\nimport numpy as np\nfrom manipulation.gpt_primitive_api import *\nfrom manipulation.gpt_reward_api import *\nimport gym\nclass {}(SimpleEnv):\n\"\"\"\nprimitive_file_header2 = \"\"\"\n    def __init__(self, task_name, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.task_name = task_name\n        self.detected_position = {}\n    def execute(self):\n\"\"\"\nprimitive_file_end = \"\"\"\n        return rgbs, final_state, success\ngym.register(\n    id='{}-v0',\n    entry_point={},\n)\n\"\"\"\ndef decompose_and_generate_reward_or_primitive(task_name, task_description, initial_config, articulation_tree, semantics, \n                              involved_links, involved_joints, object_id, yaml_config_path, save_path, \n                              temperature=0.4, model='gpt-4'):\n    query_task = \"\"\"\nTask name: {}\nDescription: {}"
        },
        {
            "comment": "This code appears to be involved in task manipulation and reward primitives generation. It begins by defining an initial configuration, links, joints, and other relevant details. The code then performs some operations on the user contents and system inputs. Afterwards, it queries the GPT model for a response, which is likely related to the task manipulation or reward primitive generation. The response is split into separate lines and processed further to identify substep names, parse rewards, and generate action spaces based on the output from the GPT model. The code appears to be part of a larger system that involves a task description, configuration, articulation tree, semantics, involved links, and involved joints.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":535-573",
            "content": "Initial config:\n```yaml\n{}\n```\n{}\n{}\nLinks:\n{}\nJoints:\n{}\n\"\"\".format(task_name, task_description, initial_config, articulation_tree, semantics, involved_links, involved_joints)\n    filled_user_contents = copy.deepcopy(user_contents)\n    filled_user_contents[-1] = filled_user_contents[-1] + query_task\n    system = \"You are a helpful assistant.\"\n    reward_response = query(system, filled_user_contents, assistant_contents, save_path=save_path, debug=False, \n                            temperature=temperature, model=model)\n    res = reward_response.split(\"\\n\")\n    substeps = []\n    substep_types = []\n    reward_or_primitives = []\n    action_spaces = []\n    num_lines = len(res)\n    for l_idx, line in enumerate(res):\n        line = line.lower()\n        if line.startswith(\"substep\"):\n            substep_name = line.split(\":\")[1]\n            substeps.append(substep_name)\n            py_start_idx, py_end_idx = l_idx, l_idx\n            for l_idx_2 in range(l_idx + 1, num_lines):\n                ### this is a reward\n                if res[l_idx_2].lower().startswith(\"```reward\"):"
        },
        {
            "comment": "This code identifies different types of sub-steps within a prompt: \"reward\", \"primitive\", and \"action space\". It extracts lines between \"```\" markdown fences and checks if the line starts with certain keywords to determine the sub-step type. The extracted lines are then processed further based on their type.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":574-597",
            "content": "                    substep_types.append(\"reward\")\n                    py_start_idx = l_idx_2 + 1\n                    for l_idx_3 in range(l_idx_2 + 1, num_lines):\n                        if \"```\" in res[l_idx_3]:\n                            py_end_idx = l_idx_3\n                            break\n                if res[l_idx_2].lower().startswith(\"```primitive\"):\n                    substep_types.append(\"primitive\")\n                    action_spaces.append(\"None\")\n                    py_start_idx = l_idx_2 + 1\n                    for l_idx_3 in range(l_idx_2 + 1, num_lines):\n                        if \"```\" in res[l_idx_3]:\n                            py_end_idx = l_idx_3\n                            break\n                    break\n                if res[l_idx_2].lower().startswith(\"```action space\"):\n                    action_space = res[l_idx_2 + 1]\n                    action_spaces.append(action_space)\n                    break\n            reward_or_primitive_lines = res[py_start_idx:py_end_idx]\n            reward_or_primitive_lines = [line.lstrip() for line in reward_or_primitive_lines]"
        },
        {
            "comment": "This code is formatting a list of reward or primitive lines based on the last substep type. If the last substep type is 'reward', it indents the first line and leaves others unchanged. Otherwise, it indents all lines. Then it joins the formatted lines, appends to the reward_or_primitives list, saves task information, and prints relevant details for debugging or logging purposes.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":598-617",
            "content": "            if substep_types[-1] == 'reward':\n                reward_or_primitive_lines[0] = \"    \" + reward_or_primitive_lines[0]\n                for idx in range(1, len(reward_or_primitive_lines)):\n                    reward_or_primitive_lines[idx] = \"        \" + reward_or_primitive_lines[idx]\n            else:\n                for idx in range(0, len(reward_or_primitive_lines)):\n                    reward_or_primitive_lines[idx] = \"        \" + reward_or_primitive_lines[idx]\n            reward_or_primitive = \"\\n\".join(reward_or_primitive_lines) + \"\\n\"\n            reward_or_primitives.append(reward_or_primitive)\n    task_name = task_name.replace(\" \", \"_\")\n    parent_folder = os.path.dirname(os.path.dirname(save_path))\n    task_save_path = os.path.join(parent_folder, \"task_{}\".format(task_name))\n    if not os.path.exists(task_save_path):\n        os.makedirs(task_save_path)\n    print(\"substep: \", substeps)\n    print(\"substep types: \", substep_types)\n    print(\"reward or primitives: \", reward_or_primitives)"
        },
        {
            "comment": "Writes the action spaces, substeps, substep types, and configuration path to separate files. Then, for each reward or primitive in the provided list, it creates a file with the corresponding header and footer formatted by the substep name and content, and writes the reward/primitive to the file.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":618-638",
            "content": "    print(\"action spaces: \", action_spaces)\n    with open(os.path.join(task_save_path, \"substeps.txt\"), \"w\") as f:\n        f.write(\"\\n\".join(substeps))\n    with open(os.path.join(task_save_path, \"substep_types.txt\"), \"w\") as f:\n        f.write(\"\\n\".join(substep_types))\n    with open(os.path.join(task_save_path, \"action_spaces.txt\"), \"w\") as f:\n        f.write(\"\\n\".join(action_spaces))\n    with open(os.path.join(task_save_path, \"config_path.txt\"), \"w\") as f:\n        f.write(yaml_config_path)\n    for idx, (substep, type, reward_or_primitive) in enumerate(zip(substeps, substep_types, reward_or_primitives)):\n        substep = substep.lstrip().replace(\" \", \"_\")\n        substep = substep.replace(\"'\", \"\")\n        file_name = os.path.join(task_save_path, f\"{substep}.py\")\n        if type == 'reward':\n            header = reward_file_header1.format(substep)\n            end = reward_file_end.format(substep, substep)\n            file_content =  header + reward_file_header2 + reward_or_primitive + end\n            with open(file_name, \"w\") as f:"
        },
        {
            "comment": "This code segment writes a file with specific content based on the type. If the type is 'primitive', it constructs the file content by combining a header, some template placeholders, and either another primitive or reward information. The constructed content is then written to the specified file name. Finally, it returns the task save path.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_manipulation_reward_primitive.py\":639-647",
            "content": "                f.write(file_content)\n        elif type == 'primitive':\n            header = primitive_file_header1.format(substep)\n            end = primitive_file_end.format(substep, substep)\n            file_content = header + primitive_file_header2 + reward_or_primitive + end\n            with open(file_name, \"w\") as f:\n                f.write(file_content)\n    return task_save_path"
        }
    ]
}