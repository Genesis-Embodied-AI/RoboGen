{
    "summary": "The code initializes a PyBullet-based simulation, sets physics parameters, configures reinforcement learning spaces, adjusts object positions, handles collisions, and updates the robot's environment, managing object placement, collision checks, joint angles, camera setup, inverse kinematics, rotation types with suction activation, contact detection, identifies objects, creates constraints, retrieves entity data, grips angle control, suction control, observation space, reward computation, and provides necessary information in a simulated robotics environment.",
    "details": [
        {
            "comment": "The code imports necessary libraries and classes for a manipulation simulation environment. It defines a SimpleEnv class that serves as a gym environment, allowing for control of a robot arm with various parameters such as time step, configuration file path, graphical user interface settings, frameskip, horizon, state file path, rotation and translation modes, maximum allowable rotations and translations, and whether to use a suction gripper.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":0-28",
            "content": "import numpy as np\nimport pybullet as p\nimport gym\nfrom gym.utils import seeding\nfrom gym import spaces\nimport pickle\nimport yaml\nimport os.path as osp\nfrom collections import defaultdict\nfrom scipy.spatial.transform import Rotation as R\nfrom manipulation.panda import Panda\nfrom manipulation.ur5 import UR5\nfrom manipulation.sawyer import Sawyer\nfrom manipulation.utils import parse_config, load_env, download_and_parse_objavarse_obj_from_yaml_config\nfrom manipulation.gpt_reward_api import get_joint_id_from_name, get_link_id_from_name\nclass SimpleEnv(gym.Env):\n    def __init__(self, \n                    dt=0.01, \n                    config_path=None, \n                    gui=False, \n                    frameskip=2, \n                    horizon=120, \n                    restore_state_file=None, \n                    rotation_mode='delta-axis-angle-local',\n                    translation_mode='delta-translation', \n                    max_rotation=np.deg2rad(5), \n                    max_translation=0.15,\n                    use_suction=True,  # whether to use a suction gripper"
        },
        {
            "comment": "The code snippet initializes a class instance with various parameters such as object candidates, collision detection, scene randomization, and object selection. It sets up the task, physics engine settings, and other relevant configurations for the simulation environment.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":29-52",
            "content": "                    object_candidate_num=6, # how many candidate objects to sample from objaverse\n                    vhacd=False, # if to perform vhacd on the object for better collision detection for pybullet\n                    randomize=0, # if to randomize the scene\n                    obj_id=0, # which object to choose to use from the candidates\n                ):\n        super().__init__()\n        # Task\n        self.config_path = config_path\n        self.restore_state_file = restore_state_file\n        self.frameskip = frameskip\n        self.horizon = horizon\n        self.gui = gui\n        self.object_candidate_num = object_candidate_num\n        self.solution_path = None        \n        self.success = False # not really used, keeped for now\n        self.primitive_save_path = None # to be used for saving the primitives execution results\n        self.randomize = randomize\n        self.obj_id = obj_id # which object to choose to use from the candidates\n        # physics\n        self.gravity = -9.81\n        self.contact_constraint = None"
        },
        {
            "comment": "This code is initializing the simulation environment. It sets up a PyBullet physics engine and configures various parameters such as action space, asset directory, time step, and camera settings for the simulated scene. It also establishes a connection with the physics client based on whether the GUI flag is set or not.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":53-83",
            "content": "        self.vhacd = vhacd\n        # action space\n        self.use_suction = use_suction\n        self.rotation_mode = rotation_mode\n        self.translation_mode = translation_mode\n        self.max_rotation_angle = max_rotation\n        self.max_translation = max_translation\n        self.suction_to_obj_pose = 0\n        self.suction_contact_link = None\n        self.suction_obj_id = None\n        self.activated = 0\n        if self.gui:\n            try:\n                self.id = p.connect(p.GUI)\n            except:\n                self.id = p.connect(p.DIRECT)\n        else:\n            self.id = p.connect(p.DIRECT)\n        self.asset_dir = osp.join(osp.dirname(osp.realpath(__file__)), \"assets/\")\n        hz=int(1/dt)\n        p.setTimeStep(1.0 / hz, physicsClientId=self.id)\n        self.seed()\n        self.set_scene()\n        self.setup_camera_rpy()\n        self.scene_lower, self.scene_upper = self.get_scene_bounds()\n        self.scene_center = (self.scene_lower + self.scene_upper) / 2\n        self.scene_range = (self.scene_upper - self.scene_lower) / 2"
        },
        {
            "comment": "This code is setting up the action space for a manipulation task. The action_low and action_high arrays define the minimum and maximum values that the action can take. The action_space variable is of type spaces.Box, indicating it's a box-type observation space. The base_action_space is also set to be the same as the action_space. The code calculates the number of objects in the scene by excluding distractor objects and then defines the observation space for reinforcement learning policy learning. This includes object positions, orientations, bounding boxes, joint angles, link positions and orientations, and robot base position.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":85-100",
            "content": "        self.grasp_action_mag = 0.06 if not self.use_suction else 1\n        self.action_low = np.array([-1, -1, -1, -1, -1, -1, -1])\n        self.action_high = np.array([1, 1, 1, 1, 1, 1, self.grasp_action_mag])\n        self.action_space = spaces.Box(low=self.action_low, high=self.action_high, dtype=np.float32) \n        self.base_action_space = spaces.Box(low=self.action_low, high=self.action_high, dtype=np.float32) \n        self.num_objects = len(self.urdf_ids) - 2 # exclude plane, robot\n        distractor_object_num = np.sum(list(self.is_distractor.values()))\n        self.num_objects -= distractor_object_num\n        ### For RL policy learning, observation space includes:\n        # 1. object positions and orientations (6 * num_objects)\n        # 2. object min and max bounding box (6 * num_objects)\n        # 3. articulated object joint angles (num_objects * num_joints) \n        # 4. articulated object link position and orientation (num_objects * num_joints * 6) \n        # 5. robot base position (xy)"
        },
        {
            "comment": "This code initializes observation spaces for the robot's environment. It calculates the number of observations needed (num_obs) based on the number of objects and joints in the scene. The 'self.observation_space' and 'self.base_observation_space' variables are defined to store these observation spaces, which can later be used by the program for decision-making or data processing.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":101-119",
            "content": "        # 6. robot end-effector position and orientation (6)\n        # 7. gripper suction activated/deactivate or gripper joint angle (if not using suction gripper) (1)\n        num_obs = self.num_objects * 12 # obs 1 and 2\n        for name in self.urdf_types:\n            if self.urdf_types[name] == 'urdf' and not self.is_distractor[name]: # obs 3 and 4\n                num_joints = p.getNumJoints(self.urdf_ids[name], physicsClientId=self.id) \n                num_obs += num_joints\n                num_obs += 6 * num_joints\n        num_obs += 2 + 6 + 1 # obs 5 6 7\n        self.base_num_obs = num_obs\n        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_obs, ), dtype=np.float32) \n        self.base_observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.base_num_obs, ), dtype=np.float32)\n        self.detected_position = {} # not used for now, keep it\n    def normalize_position(self, pos):\n        if self.translation_mode == 'normalized-direct-translation':\n            return (pos - self.scene_center) / self.scene_range "
        },
        {
            "comment": "The code is part of the RoboGen library's manipulation module. It initializes a simulation, sets a seed for the random number generator, and retrieves the Axis Aligned Bounding Box (AABB) information from the physics engine for each link in a robot model. The function get_scene_bounds() collects this data to calculate the overall bounds of the scene excluding a 'plane' object, presumably used for simulation area.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":120-146",
            "content": "        else:\n            return pos\n    def seed(self, seed=None):\n        self.np_random, _ = seeding.np_random()\n    def get_aabb(self, id):\n        num_joints = p.getNumJoints(id, physicsClientId=self.id)\n        min_aabbs, max_aabbs = [], []\n        for link_idx in range(-1, num_joints):\n            min_aabb, max_aabb = p.getAABB(id, link_idx, physicsClientId=self.id)\n            min_aabbs.append(list(min_aabb))\n            max_aabbs.append(list(max_aabb))\n        min_aabb = np.min(np.concatenate(min_aabbs, axis=0).reshape(-1, 3), axis=0)\n        max_aabb = np.max(np.concatenate(max_aabbs, axis=0).reshape(-1, 3), axis=0)\n        return min_aabb, max_aabb\n    def get_aabb_link(self, id, link_id):\n        min_aabb, max_aabb = p.getAABB(id, link_id, physicsClientId=self.id)\n        return np.array(min_aabb), np.array(max_aabb)\n    def get_scene_bounds(self):\n        min_aabbs = []\n        max_aabbs = []\n        for name, id in self.urdf_ids.items():\n            if name == 'plane': continue\n            min_aabb, max_aabb = self.get_aabb(id)"
        },
        {
            "comment": "The code calculates the minimum and maximum aabb bounds for a set of points. It then defines a range and returns the adjusted min and max aabb values. The clip_within_workspace function clips the position of an object within the workspace, either pushing it away from the robot if it's not on the table or ensuring it stays within the table's bounding box if it is on the table.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":147-169",
            "content": "            min_aabbs.append(min_aabb)\n            max_aabbs.append(max_aabb)\n        min_aabb = np.min(np.stack(min_aabbs, axis=0).reshape(-1, 3), axis=0)\n        max_aabb = np.max(np.stack(max_aabbs, axis=0).reshape(-1, 3), axis=0)\n        range = max_aabb - min_aabb\n        return min_aabb - 0.5 * range, max_aabb + 0.5 * range\n    def clip_within_workspace(self, robot_pos, ori_pos, on_table):\n        pos = ori_pos.copy()\n        if not on_table:\n            # If objects are too close to the robot, push them away\n            x_near_low, x_near_high = robot_pos[0] - 0.3, robot_pos[0] + 0.3\n            y_near_low, y_near_high = robot_pos[1] - 0.3, robot_pos[1] + 0.3\n            if pos[0] > x_near_low and pos[0] < x_near_high:\n                pos[0] = x_near_low if pos[0] < robot_pos[0] else x_near_high\n            if pos[1] > y_near_low and pos[1] < y_near_high:\n                pos[1] = y_near_low if pos[1] < robot_pos[1] else y_near_high\n            return pos\n        else:\n            # Object is on table, should be within table's bounding box"
        },
        {
            "comment": "The code snippet is from the \"RoboGen/manipulation/sim.py\" file, which seems to be related to a robot simulator. It contains three functions: 1) `new_pos` that clips position coordinates within the table's bounds, 2) `get_robot_base_pos` returns a fixed base position for the robot, and 3) `set_scene` resets the simulation environment and camera view. The code also initializes a physicsClientId for the simulation and GUI settings.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":170-193",
            "content": "            new_pos = pos.copy()\n            new_pos[:2] = np.clip(new_pos[:2], self.table_bbox_min[:2], self.table_bbox_max[:2])\n            return new_pos\n    def get_robot_base_pos(self):\n        robot_base_pos = [1, 1, 0.28]\n        return robot_base_pos\n    def get_robot_init_joint_angles(self):\n        init_joint_angles = [0 for _ in range(len(self.robot.right_arm_joint_indices))]\n        if self.robot_name == 'panda':\n            init_joint_angles = [0, -1.10916842e-04,  7.33823451e-05, -5.47701370e-01, -5.94950533e-01,\n                2.62857916e+00, -4.85316284e-01,  1.96042022e+00,  2.15271531e+00,\n                -7.35304443e-01]\n        return init_joint_angles\n    def set_scene(\n        self,\n    ):\n        ### simulation preparation\n        p.resetSimulation(physicsClientId=self.id)\n        if self.gui:\n            p.resetDebugVisualizerCamera(cameraDistance=1.75, cameraYaw=-25, cameraPitch=-45, cameraTargetPosition=[-0.2, 0, 0.4], physicsClientId=self.id)\n            p.configureDebugVisualizer(p.COV_ENABLE_MOUSE_PICKING, 0, physicsClientId=self.id)"
        },
        {
            "comment": "Initializes physics simulation environment, loads plane and robot model, and sets up initial positions for objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":194-220",
            "content": "            p.configureDebugVisualizer(p.COV_ENABLE_GUI, 0, physicsClientId=self.id)\n        p.setRealTimeSimulation(0, physicsClientId=self.id)\n        p.setGravity(0, 0, self.gravity, physicsClientId=self.id)\n        ### load restore state\n        restore_state = None\n        if self.restore_state_file is not None:\n            with open(self.restore_state_file, 'rb') as f:\n                restore_state = pickle.load(f)\n        ### load plane \n        planeId = p.loadURDF(osp.join(self.asset_dir, \"plane\", \"plane.urdf\"), physicsClientId=self.id)\n        ### create and load a robot\n        robot_base_pos = self.load_robot(restore_state)\n        ### load and parse task config (including semantically meaningful distractor objects)\n        self.urdf_ids = {\n            \"robot\": self.robot.body,\n            \"plane\": planeId,\n        }\n        self.urdf_paths = {}\n        self.urdf_types = {}\n        self.init_positions = {}\n        self.on_tables = {}\n        self.simulator_sizes = {}\n        self.is_distractor = {"
        },
        {
            "comment": "This code initializes the simulation environment by loading and parsing configuration, handling tables if present, loading objects based on configs, adjusting object positions, resolving collisions, and handling special relationships outputted by GPT.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":221-243",
            "content": "            \"robot\": 0,\n            \"plane\": 0,\n        }\n        urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, urdf_movables, \\\n            use_table, articulated_init_joint_angles, spatial_relationships = self.load_and_parse_config(restore_state)\n        ### handle the case if there is a table\n        self.load_table(use_table, restore_state)\n        ### load each object from the task config\n        self.load_object(urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, urdf_movables)\n        ### adjusting object positions\n        ### place the lowest point on the object to be the height where GPT specifies\n        object_height = self.adjust_object_positions(robot_base_pos)\n        ### resolve collisions between objects\n        self.resolve_collision(robot_base_pos, object_height, spatial_relationships)\n        ### handle any special relationships outputted by GPT\n        self.handle_gpt_special_relationships(spatial_relationships)\n        ### set all object's joint angles to the lower joint limit"
        },
        {
            "comment": "The code initializes a simulation, overwrites joint angles if specified by GPT, records initial joint angles and positions, stabilizes the scene, restores state from file (if provided), enables debug rendering, saves the initial state, and loads a random robot class based on the given inputs.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":244-275",
            "content": "        self.set_to_default_joint_angles()\n        ### overwrite joint angles specified by GPT\n        self.handle_gpt_joint_angle(articulated_init_joint_angles)\n        ### record initial joint angles and positions\n        self.record_initial_joint_and_pose()\n        ### stabilize the scene\n        for _ in range(500):\n            p.stepSimulation(physicsClientId=self.id)\n        ### restore to a state if provided\n        if self.restore_state_file is not None:\n            load_env(self, self.restore_state_file)\n        ### Enable debug rendering\n        if self.gui:\n            p.configureDebugVisualizer(p.COV_ENABLE_RENDERING, 1, physicsClientId=self.id)\n        self.init_state = p.saveState(physicsClientId=self.id)\n    def load_robot(self, restore_state):\n        robot_classes = {\n            \"panda\": Panda,\n            \"sawyer\": Sawyer,\n            \"ur5\": UR5,\n        }\n        robot_names = list(robot_classes.keys())\n        self.robot_name = robot_names[np.random.randint(len(robot_names))]\n        if restore_state is not None and \"robot_name\" in restore_state:"
        },
        {
            "comment": "This code initializes a robot object, sets its motor gains and forces, base position and orientation, and joint angles based on the given restore_state. It returns the base position of the robot.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":276-299",
            "content": "            self.robot_name = restore_state['robot_name']\n        self.robot_class = robot_classes[self.robot_name]\n        # Create robot\n        self.robot = self.robot_class()\n        self.robot.init(self.asset_dir, self.id, self.np_random, fixed_base=True, use_suction=self.use_suction)\n        self.agents = [self.robot]\n        self.suction_id = self.robot.right_gripper_indices[0]\n        # Update robot motor gains\n        self.robot.motor_gains = 0.05\n        self.robot.motor_forces = 100.0\n        # Set robot base position & orientation, and joint angles\n        robot_base_pos = self.get_robot_base_pos()\n        robot_base_orient = [0, 0, 0, 1]\n        self.robot_base_orient = robot_base_orient\n        self.robot.set_base_pos_orient(robot_base_pos, robot_base_orient)\n        init_joint_angles = self.get_robot_init_joint_angles()\n        self.robot.set_joint_angles(self.robot.right_arm_joint_indices, init_joint_angles)    \n        return robot_base_pos        \n    def load_and_parse_config(self, restore_state):"
        },
        {
            "comment": "Code snippet selects and downloads objects from Objaverse, parses the config file, and stores necessary information for task execution.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":300-320",
            "content": "        ### select and download objects from objaverse\n        res = download_and_parse_objavarse_obj_from_yaml_config(self.config_path, candidate_num=self.object_candidate_num, vhacd=self.vhacd)\n        if not res:\n            print(\"=\" * 20)\n            print(\"some objects cannot be found in objaverse, task_build failed, now exit ...\")\n            print(\"=\" * 20)\n            exit()\n        self.config = None\n        while self.config is None:\n            with open(self.config_path, 'r') as file:\n                self.config = yaml.safe_load(file)\n        for obj in self.config:\n            if \"solution_path\" in obj:\n                self.solution_path = obj[\"solution_path\"]\n                break\n        ### parse config\n        urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, use_table, \\\n            articulated_init_joint_angles, spatial_relationships, distractor_config_path, urdf_movables = parse_config(self.config, \n                        use_bard=True, obj_id=self.obj_id)"
        },
        {
            "comment": "If \"use_table\" is False, set all \"urdf_on_table\" values to False. Convert \"urdf_names\" and \"distractor_urdf_names\" to lowercase. Initialize \"is_distractor\" for each \"urdf_name\". Download and parse the distractor object config if \"distractor_config_path\" is not None. Extract distractor urdf data using \"parse_config()\", convert \"distractor_urdf_names\" to lowercase.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":321-336",
            "content": "        if not use_table:\n            urdf_on_table = [False for _ in urdf_on_table]\n        urdf_names = [x.lower() for x in urdf_names]\n        for name in urdf_names:\n            self.is_distractor[name] = 0\n        ### parse distractor object config (semantically meaningful objects that are related but not used for the task)\n        if distractor_config_path is not None:\n            self.distractor_config_path = distractor_config_path\n            res = download_and_parse_objavarse_obj_from_yaml_config(distractor_config_path, candidate_num=self.object_candidate_num, vhacd=self.vhacd)\n            with open(distractor_config_path, 'r') as f:\n                self.distractor_config = yaml.safe_load(f)\n            distractor_urdf_paths, distractor_urdf_sizes, distractor_urdf_positions, distractor_urdf_names, distractor_urdf_types, \\\n                distractor_urdf_on_table, _, _, _, _, _ = \\\n                    parse_config(self.distractor_config, use_bard=True, obj_id=self.obj_id, use_vhacd=False)\n            distractor_urdf_names = [x.lower() for x in distractor_urdf_names]"
        },
        {
            "comment": "The code handles adding distractor URDFs to the simulation and updating the state if a restore_state is present. It ensures all URDF-related lists are updated with corresponding distractor information, and it checks if 'urdf_paths' and 'object_sizes' exist in the restore_state dictionary to update the urdf_paths and urdf_sizes accordingly.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":337-359",
            "content": "            if not use_table:\n                distractor_urdf_on_table = [False for _ in distractor_urdf_on_table]\n            for name in distractor_urdf_names:\n                self.is_distractor[name] = 1\n            distractor_movables = [True for _ in distractor_urdf_names]\n            urdf_paths += distractor_urdf_paths\n            urdf_sizes += distractor_urdf_sizes\n            urdf_positions += distractor_urdf_positions\n            urdf_names += distractor_urdf_names\n            urdf_types += distractor_urdf_types\n            urdf_on_table += distractor_urdf_on_table\n            urdf_movables += distractor_movables\n        if restore_state is not None:\n            if \"urdf_paths\" in restore_state:\n                self.urdf_paths = restore_state['urdf_paths']\n                urdf_paths = [self.urdf_paths[name] for name in urdf_names]\n            if \"object_sizes\" in restore_state:\n                self.simulator_sizes = restore_state['object_sizes']\n                urdf_sizes = [self.simulator_sizes[name] for name in urdf_names]"
        },
        {
            "comment": "Function \"load_table\" sets the table path based on a random choice and scale, then loads the table object into the physics engine with the chosen path and scale. If randomization is not enabled, it also sets the orientation to a specific value (np.pi/2, 0, 0). The function takes in use_table boolean and optional restore_state dictionary as parameters.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":361-380",
            "content": "        return urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, urdf_movables, \\\n            use_table, articulated_init_joint_angles, spatial_relationships\n    def load_table(self, use_table, restore_state):\n        self.use_table = use_table\n        if use_table:\n            from manipulation.table_utils import table_paths, table_scales, table_poses, table_bbox_scale_down_factors\n            self.table_path = table_paths[np.random.randint(len(table_paths))]\n            if restore_state is not None:\n                self.table_path = restore_state['table_path']\n            table_scale = table_scales[self.table_path] \n            table_pos = table_poses[self.table_path]\n            table_orientation = [np.pi/2, 0, 0]\n            self.table = p.loadURDF(osp.join(self.asset_dir, self.table_path, \"material.urdf\"), physicsClientId=self.id, useFixedBase=True, \n                                    globalScaling=table_scale)\n            if not self.randomize:\n                random_orientation = p.getQuaternionFromEuler(table_orientation, physicsClientId=self.id)"
        },
        {
            "comment": "The code sets a random orientation for the table, resets its position and orientation using PyBullet physics engine, adjusts the table's bounding box based on scale-down factors, adds a debug line to visualize the table dimensions, and saves the initial size and URDF (Unified Robot Description Format) ID of the table.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":381-394",
            "content": "            else:\n                random_orientations = [0, np.pi / 2, np.pi, np.pi * 3 / 2]\n                random_orientation = p.getQuaternionFromEuler([np.pi/2, 0, random_orientations[np.random.randint(4)]], physicsClientId=self.id)\n            p.resetBasePositionAndOrientation(self.table, table_pos, random_orientation, physicsClientId=self.id)\n            self.table_bbox_min, self.table_bbox_max = self.get_aabb(self.table)\n            table_range = self.table_bbox_max - self.table_bbox_min\n            self.table_bbox_min[:2] += table_range[:2] * table_bbox_scale_down_factors[self.table_path]\n            self.table_bbox_max[:2] -= table_range[:2] * table_bbox_scale_down_factors[self.table_path]\n            self.table_height = self.table_bbox_max[2]\n            p.addUserDebugLine([*self.table_bbox_min[:2], self.table_height], self.table_bbox_max, [1, 0, 0], lineWidth=10, lifeTime=0, physicsClientId=self.id)\n            self.simulator_sizes[\"init_table\"] = table_scale\n            self.urdf_ids[\"init_table\"] = self.table"
        },
        {
            "comment": "This code initializes the manipulation of objects in a simulation. It checks if the object type is \"urdf\" and whether it should be movable or fixed based on user input. The size of the object is set between 0.1 and 1.2 to ensure it can be manipulated by the gripper. The orientation is set depending on the object's source, either from objaverse or Partnet-mobility.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":395-409",
            "content": "            self.is_distractor['init_table'] = 0\n    def load_object(self, urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, urdf_movables):\n        for path, size, pos, name, type, on_table, moveable in zip(urdf_paths, urdf_sizes, urdf_positions, urdf_names, urdf_types, urdf_on_table, urdf_movables):\n            name = name.lower()\n            # by default, all objects movable, except the urdf files\n            use_fixed_base = (type == 'urdf' and not self.is_distractor[name])\n            if type == 'urdf' and moveable: # if gpt specified the object is movable, then it is movable\n                use_fixed_base = False\n            size = min(size, 1.2)\n            size = max(size, 0.1) # if the object is too small, current gripper cannot really manipulate it.\n            x_orient = np.pi/2 if type == 'mesh' else 0 # handle different coordinate axis by objaverse and partnet-mobility\n            if self.randomize or self.is_distractor[name]:\n                orientation ="
        },
        {
            "comment": "This code sets the orientation and position of a 3D object in the simulation environment. It loads the URDF model, applies scaling if necessary, and adjusts the object's position based on whether it is placed on a table or not. The orientation is determined by either euler angles or quaternion conversion depending on certain conditions.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":409-427",
            "content": " p.getQuaternionFromEuler([x_orient, 0, self.np_random.uniform(-np.pi/3, np.pi/3)], physicsClientId=self.id)\n            else:\n                orientation = p.getQuaternionFromEuler([x_orient, 0, 0], physicsClientId=self.id)\n            if not on_table:\n                load_pos = pos\n            else: # change to be table coordinate\n                table_xy_range = self.table_bbox_max[:2] - self.table_bbox_min[:2]\n                obj_x = self.table_bbox_min[0] + pos[0] * table_xy_range[0]\n                obj_y = self.table_bbox_min[1] + pos[1] * table_xy_range[1]\n                obj_z = self.table_height\n                load_pos = [obj_x, obj_y, obj_z]\n            id = p.loadURDF(path, basePosition=load_pos, baseOrientation=orientation, physicsClientId=self.id, useFixedBase=use_fixed_base, globalScaling=size)\n            # scale size \n            if name in self.simulator_sizes:\n                p.removeBody(id, physicsClientId=self.id)\n                saved_size = self.simulator_sizes[name]\n          "
        },
        {
            "comment": "This code loads a URDF (Universal Robot Description Format) model into the PyBullet simulator, handles potential size discrepancies, and stores relevant information for future use. If the loaded object's size is different from the expected size, it removes the old object and reloads it with the correct size. It then stores the URDF ID, path, type, initial position, and whether the object is on a table.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":427-444",
            "content": "      id = p.loadURDF(path, basePosition=load_pos, baseOrientation=orientation, physicsClientId=self.id, useFixedBase=use_fixed_base, globalScaling=saved_size)\n            else:\n                min_aabb, max_aabb = self.get_aabb(id)\n                actual_size = np.linalg.norm(max_aabb - min_aabb)\n                if np.abs(actual_size - size) > 0.05:\n                    p.removeBody(id, physicsClientId=self.id)\n                    id = p.loadURDF(path, basePosition=load_pos, baseOrientation=orientation, physicsClientId=self.id, useFixedBase=use_fixed_base, globalScaling=size ** 2 / actual_size)\n                    self.simulator_sizes[name] = size ** 2 / actual_size\n                else:\n                    self.simulator_sizes[name] = size\n            self.urdf_ids[name] = id\n            self.urdf_paths[name] = path\n            self.urdf_types[name] = type\n            self.init_positions[name] = np.array(load_pos)\n            self.on_tables[name] = on_table\n            print(\"Finished loading object: \", name)"
        },
        {
            "comment": "The \"adjust_object_positions\" function sets object heights based on minimum and maximum bounding box coordinates, clips positions within workspace limits, adjusts the Z-coordinate of each object to match its height, and resets the object's position and orientation. The \"resolve_collision\" function continuously attempts to resolve collisions by iterating until no collision exists; if not resolved in 50 iterations, it randomly resets an object's position.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":446-466",
            "content": "    def adjust_object_positions(self, robot_base_pos):\n        object_height = {}\n        for name, id in self.urdf_ids.items():\n            if name == 'robot' or name == 'plane' or name == 'init_table': continue\n            min_aabb, max_aabb = self.get_aabb(id)\n            min_z = min_aabb[2]\n            object_height[id] = 2 * self.init_positions[name][2] - min_z\n            pos, orient = p.getBasePositionAndOrientation(id, physicsClientId=self.id)\n            new_pos = np.array(pos) \n            new_pos = self.clip_within_workspace(robot_base_pos, new_pos, self.on_tables[name])\n            new_pos[2] = object_height[id]\n            p.resetBasePositionAndOrientation(id, new_pos, orient, physicsClientId=self.id)\n            self.init_positions[name] = new_pos\n        return object_height\n    def resolve_collision(self, robot_base_pos, object_height, spatial_relationships):\n        collision = True\n        collision_cnt = 1\n        while collision:\n            if collision_cnt % 50 == 0: # if collision is not resolved every 50 iterations, we randomly reset object's position"
        },
        {
            "comment": "Iterates over each object in the simulation, ignoring \"robot\", \"plane\", and \"init_table\". Resets positions of objects randomly within workspace boundaries. Updates object heights to object_height values. Detects collisions between all objects except 'robot', 'plane' and 'init_table'.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":467-483",
            "content": "                for name, id in self.urdf_ids.items():\n                    if name == 'robot' or name == 'plane' or name == \"init_table\": continue\n                    pos = self.init_positions[name]\n                    _, orient = p.getBasePositionAndOrientation(id, physicsClientId=self.id)\n                    new_pos = np.array(pos) + np.random.uniform(-0.2, 0.2, size=3)\n                    new_pos = self.clip_within_workspace(robot_base_pos, new_pos, self.on_tables[name])\n                    new_pos[2] = object_height[id]\n                    p.resetBasePositionAndOrientation(id, new_pos, orient, physicsClientId=self.id)\n                    p.stepSimulation(physicsClientId=self.id)\n            push_directions = defaultdict(list) # store the push direction for each object\n            # detect collisions between objects \n            detected_collision = False\n            for name, id in self.urdf_ids.items():\n                if name == 'robot' or name == 'plane' or name == 'init_table': continue\n                for name2, id2 in self.urdf_ids.items():"
        },
        {
            "comment": "This code checks if two named objects (name and name2) are in a specific relationship defined by spatial_relationships. If they are, it skips collision resolution. It then uses the PyBullet physics engine to get closest points between the two objects and obtains push direction for potential collision response.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":484-501",
            "content": "                    if name == name2 or name2 == 'robot' or name2 == 'plane' or name2 == 'init_table': continue\n                    # if gpt specifies obj a and obj b should have some special relationship, then skip collision resolution\n                    skip = False\n                    for spatial_relationship in spatial_relationships:\n                        words = spatial_relationship.lower().split(\",\")\n                        words = [word.strip().lstrip() for word in words]\n                        if name in words and name2 in words:\n                            skip = True\n                            break\n                    if skip: continue\n                    contact_points = p.getClosestPoints(id, id2, 0.01, physicsClientId=self.id)\n                    if len(contact_points) > 0:\n                        contact_point = contact_points[0]\n                        push_direction = contact_point[7]\n                        push_direction = np.array([push_direction[0], push_direction[1], push_direction[2]])"
        },
        {
            "comment": "This code segment checks for collisions between objects and the robot. If both objects are distractors or both are not, it pushes both away. If only one is a distractor, it pushes that specific object away. It also handles collisions with the 'robot', 'plane', or 'init_table' objects by excluding them from being pushed.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":503-518",
            "content": "                        # both are distractors or both are not, push both objects away\n                        if (self.is_distractor[name] and self.is_distractor[name2]) or \\\n                            (not self.is_distractor[name] and not self.is_distractor[name2]):\n                            push_directions[id].append(-push_direction)\n                            push_directions[id2].append(push_direction)\n                        # only 1 is distractor, only pushes the distractor\n                        if self.is_distractor[name] and not self.is_distractor[name2]:\n                            push_directions[id].append(push_direction)\n                        if not self.is_distractor[name] and self.is_distractor[name2]:\n                            push_directions[id2].append(-push_direction)\n                        detected_collision = True\n            # collisions between robot and objects, only push object away\n            for name, id in self.urdf_ids.items():\n                if name == 'robot' or name == 'plane' or name == 'init_table': "
        },
        {
            "comment": "Continuing through the loop, if a collision is detected with an object other than 'robot', 'plane', or 'init_table' and not on the table, it will retrieve the closest contact points, store the push direction, and add it to the push directions array. This allows for collision response by applying force in the opposite direction of the collision.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":519-539",
            "content": "                    continue\n                contact_points = p.getClosestPoints(self.robot.body, id, 0.05, physicsClientId=self.id)\n                if len(contact_points) > 0:\n                    contact_point = contact_points[0]\n                    push_direction = contact_point[7]\n                    push_direction = np.array([push_direction[0], push_direction[1], push_direction[2]])\n                    push_directions[id].append(-push_direction)\n                    detected_collision = True\n            # between table and objects that should not be placed on table\n            if self.use_table:\n                for name, id in self.urdf_ids.items():\n                    if name == 'robot' or name == 'plane' or name == 'init_table': \n                        continue\n                    if self.on_tables[name]:\n                        continue\n                    contact_points = p.getClosestPoints(self.robot.body, id, 0.05, physicsClientId=self.id)\n                    if len(contact_points) > 0:\n                        contact_point = contact_points[0]"
        },
        {
            "comment": "This code segment is responsible for detecting and resolving collisions in a simulation. It calculates push directions based on contact points, moves objects accordingly to avoid collisions, and maintains a count of detected collisions. If more than 1000 collisions are detected, it stops the execution.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":540-560",
            "content": "                        push_direction = contact_point[7]\n                        push_direction = np.array([push_direction[0], push_direction[1], push_direction[2]])\n                        push_directions[id].append(-push_direction)\n                        detected_collision = True\n            # move objects\n            push_distance = 0.1\n            for id in push_directions:\n                for direction in push_directions[id]:\n                    pos, orient = p.getBasePositionAndOrientation(id, physicsClientId=self.id)\n                    new_pos = np.array(pos) + push_distance * direction    \n                    new_pos = self.clip_within_workspace(robot_base_pos, new_pos, self.on_tables[name])\n                    new_pos[2] = object_height[id]\n                    p.resetBasePositionAndOrientation(id, new_pos, orient, physicsClientId=self.id)\n                    p.stepSimulation(physicsClientId=self.id)\n            collision = detected_collision\n            collision_cnt += 1\n            if collision_cnt > 1000:"
        },
        {
            "comment": "This code is part of the \"record_initial_joint_and_pose\" function. It initializes a dictionary to store joint angles and positions/orientations of non-robot, non-plane objects (like init_table). First, it loops through each object's URDF ID, then checks its type as 'urdf'. If the object is a robot or plane, it skips. For each object, it retrieves joint names and angles, and stores them in a dictionary for further use. Finally, it initializes dictionaries to store position and orientation data of these objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":561-580",
            "content": "                break\n    def record_initial_joint_and_pose(self):\n        self.initial_joint_angle = {}\n        for name in self.urdf_ids:        \n            obj_id = self.urdf_ids[name.lower()]\n            if name == 'robot' or name == 'plane' or name == \"init_table\": continue\n            if self.urdf_types[name.lower()] == 'urdf':\n                self.initial_joint_angle[name] = {}\n                num_joints = p.getNumJoints(obj_id, physicsClientId=self.id)\n                for joint_idx in range(num_joints):\n                    joint_name = p.getJointInfo(obj_id, joint_idx, physicsClientId=self.id)[1].decode(\"utf-8\")\n                    joint_angle = p.getJointState(obj_id, joint_idx, physicsClientId=self.id)[0]\n                    self.initial_joint_angle[name][joint_name] = joint_angle\n        self.initial_pos = {}\n        self.initial_orient = {}\n        for name in self.urdf_ids:\n            obj_id = self.urdf_ids[name.lower()]\n            if name == 'robot' or name == 'plane' or name == \"init_table\": continue"
        },
        {
            "comment": "The code retrieves the base position and orientation of an object using the physics engine. It then stores these values in a dictionary for later use. The set_to_default_joint_angles function sets the joint angles of certain objects to their default values by iterating over each joint, calculating the joint's default angle based on its limits, and resetting the joint state accordingly. The handle_gpt_special_relationships function handles any special relationships defined by a GPT model by processing the spatial_relationships argument.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":581-597",
            "content": "            pos, orient = p.getBasePositionAndOrientation(obj_id, physicsClientId=self.id)\n            self.initial_pos[name] = pos\n            self.initial_orient[name] = orient\n    def set_to_default_joint_angles(self):\n        for obj_name in self.urdf_ids:\n            if obj_name == 'robot' or obj_name == 'plane' or obj_name == \"init_table\": continue\n            obj_id = self.urdf_ids[obj_name]\n            num_joints = p.getNumJoints(obj_id, physicsClientId=self.id)\n            for joint_idx in range(num_joints):\n                joint_limit_low, joint_limit_high = p.getJointInfo(obj_id, joint_idx, physicsClientId=self.id)[8:10]\n                if joint_limit_low > joint_limit_high:\n                    joint_limit_low, joint_limit_high = joint_limit_high, joint_limit_low\n                joint_val = joint_limit_low + 0.06 * (joint_limit_high - joint_limit_low)\n                p.resetJointState(obj_id, joint_idx, joint_val, physicsClientId=self.id)\n    def handle_gpt_special_relationships(self, spatial_relationships):"
        },
        {
            "comment": "Code snippet creates a function to handle spatial relationships between objects. It supports \"on\" and \"in\" for now, but can be extended later. It iterates over the list of spatial relationships, strips whitespace, and identifies if it is an \"on\" relationship. Then it gets object IDs from URDF names, bounding box details, target AABB, and adds a debug line in Pybullet physics client with the appropriate parameters.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":598-615",
            "content": "        # we support \"on\" and \"in\" for now, but this can be extended to more relationships\n        for spatial_relationship in spatial_relationships:\n            words = spatial_relationship.lower().split(\",\")\n            words = [word.strip().lstrip() for word in words]\n            if words[0] == \"on\":\n                obj_a = words[1]\n                obj_b = words[2]\n                if len(words) == 4:\n                    obj_b_link = words[3]\n                    obj_b_link_id = get_link_id_from_name(self, obj_b, obj_b_link)\n                else:\n                    obj_b_link_id = -1\n                obj_a_id, obj_b_id = self.urdf_ids[obj_a], self.urdf_ids[obj_b]\n                obj_a_bbox_min, obj_a_bbox_max = self.get_aabb(obj_a_id)\n                obj_a_size = obj_a_bbox_max - obj_a_bbox_min\n                target_aabb_min, target_aabb_max = self.get_aabb_link(obj_b_id, obj_b_link_id)\n                id_line = p.addUserDebugLine(target_aabb_min, target_aabb_max, [1, 0, 0], lineWidth=10, lifeTime=0, physicsClientId=self.id)"
        },
        {
            "comment": "This code snippet sets the position and orientation of an object A on top of another object B. If `randomize` is False, it sets the orientation to be tilted 90 degrees from the vertical axis (pi/2 radians). Otherwise, it randomly chooses a rotation angle between 0, pi/2, pi, and 3pi/2 radians. The code then resets the position and orientation of object A using physicsClientId. Finally, it removes any previously added debug items from the PhysX environment. This code appears to be part of a larger simulation script for manipulating objects in a virtual environment.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":616-632",
            "content": "                id_point = p.addUserDebugPoints([(target_aabb_min + target_aabb_max) / 2], [[0, 0, 1]], 10, 0, physicsClientId=self.id)\n                new_pos = (target_aabb_min + target_aabb_max) / 2\n                new_pos[2] = target_aabb_max[2] # put obj a on top of obj b.\n                new_pos[2] += obj_a_size[2] # add the height of obj a\n                if not self.randomize:\n                    obj_a_orientation = p.getQuaternionFromEuler([np.pi/2, 0, 0], physicsClientId=self.id)\n                else:\n                    random_orientations = [0, np.pi / 2, np.pi, np.pi * 3 / 2]\n                    obj_a_orientation = p.getQuaternionFromEuler([np.pi/2, 0, random_orientations[np.random.randint(4)]], physicsClientId=self.id)\n                p.resetBasePositionAndOrientation(obj_a_id, new_pos, obj_a_orientation, physicsClientId=self.id)\n                p.removeUserDebugItem(id_line, physicsClientId=self.id)\n                p.removeUserDebugItem(id_point, physicsClientId=self.id)\n            if words[0] == 'in':"
        },
        {
            "comment": "The code is iteratively scaling down the size of object A until there's no collision with object B. It checks for collisions between two objects and adjusts the size of object A accordingly by multiplying it with 0.9. The process continues until a collision-free state is achieved or a specific number of attempts are made (100 iterations).",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":633-652",
            "content": "                obj_a = words[1]\n                obj_b = words[2]\n                if len(words) == 4:\n                    obj_b_link = words[3]\n                    obj_b_link_id = get_link_id_from_name(self, obj_b, obj_b_link)\n                else:\n                    obj_b_link_id = -1\n                obj_a_id, obj_b_id = self.urdf_ids[obj_a], self.urdf_ids[obj_b]\n                # if after a lot of trying times, there is still collision, we should scale down the size of object A.\n                cnt = 1\n                collision_free = False\n                obj_a_new_size = self.simulator_sizes[obj_a]\n                obj_a_ori_pos, obj_a_orientation = p.getBasePositionAndOrientation(obj_a_id, physicsClientId=self.id)         \n                target_aabb_min, target_aabb_max = self.get_aabb_link(obj_b_id, obj_b_link_id)\n                while not collision_free:\n                    if cnt % 100 == 0:\n                        print(\"scaling down! object size is {}\".format(obj_a_new_size))\n                        obj_a_new_size = obj_a_new_size * 0.9"
        },
        {
            "comment": "Removes an object from the physics engine, replaces it with a new object using its URDF file and sets the ID and size of the object. Calculates the AABB of the new object and adds a debug line and point to visualize the center of the target's AABB.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":653-666",
            "content": "                        p.removeBody(obj_a_id, physicsClientId=self.id)\n                        obj_a_id = p.loadURDF(self.urdf_paths[obj_a],\n                                            basePosition=obj_a_ori_pos,\n                                            baseOrientation=obj_a_orientation,\n                                            physicsClientId=self.id, useFixedBase=False, globalScaling=obj_a_new_size)\n                        self.urdf_ids[obj_a] = obj_a_id\n                        self.simulator_sizes[obj_a] = obj_a_new_size\n                    obj_a_bbox_min, obj_a_bbox_max = self.get_aabb(obj_a_id)\n                    obj_a_size = obj_a_bbox_max - obj_a_bbox_min\n                    id_line = p.addUserDebugLine(target_aabb_min, target_aabb_max, [1, 0, 0], lineWidth=10, lifeTime=0, physicsClientId=self.id)\n                    id_point = p.addUserDebugPoints([(target_aabb_min + target_aabb_max) / 2], [[0, 0, 1]], 10, 0, physicsClientId=self.id)\n                    center_pos = (target_aabb_min + target_aabb_max) / 2"
        },
        {
            "comment": "The code tries two possible locations to place obj a inside obj b, checks for collision and sets the orientation of obj a as a quarter turn. It removes debug items and increases a counter if not successful after 10 attempts.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":667-683",
            "content": "                    up_pos = center_pos.copy()\n                    up_pos[2] += obj_a_size[2]\n                    possible_locations = [center_pos, up_pos]\n                    obj_a_orientation = p.getQuaternionFromEuler([np.pi/2, 0, 0], physicsClientId=self.id)\n                    for pos in possible_locations: # we try two possible locations to put obj a in obj b\n                        p.resetBasePositionAndOrientation(obj_a_id, pos, obj_a_orientation, physicsClientId=self.id)\n                        contact_points = p.getClosestPoints(obj_a_id, obj_b_id, 0.002, physicsClientId=self.id)\n                        if len(contact_points) == 0:\n                            collision_free = True\n                            break\n                    p.removeUserDebugItem(id_line, physicsClientId=self.id)\n                    p.removeUserDebugItem(id_point, physicsClientId=self.id)\n                    cnt += 1\n                    if cnt > 1000: # if after scaling for 10 times it still does not work, let it be. "
        },
        {
            "comment": "This code handles joint angle input for a robot manipulator. It iterates through the articulated_init_joint_angles dictionary and checks each joint's angle against its limits. If the angle is not random, it scales the angle between the lower and upper limit of the joint. Otherwise, it assigns a random value within the joint's range. The code breaks from the loop once all joint angles have been processed.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":684-702",
            "content": "                        break\n    def handle_gpt_joint_angle(self, articulated_init_joint_angles):\n        for name in articulated_init_joint_angles:\n            obj_id = self.urdf_ids[name.lower()]\n            for joint_name, joint_angle in articulated_init_joint_angles[name].items():\n                joint_idx = get_joint_id_from_name(self, name.lower(), joint_name)\n                joint_limit_low, joint_limit_high = p.getJointInfo(obj_id, joint_idx, physicsClientId=self.id)[8:10]\n                if joint_limit_low > joint_limit_high:\n                    joint_limit_low, joint_limit_high = joint_limit_high, joint_limit_low\n                if 'random' not in joint_angle:\n                    joint_angle = float(joint_angle)\n                    joint_angle = min(joint_angle, 0.7)\n                    joint_angle = max(joint_angle, 0.06)\n                    joint_angle = joint_limit_low + joint_angle * (joint_limit_high - joint_limit_low)\n                else:\n                    joint_angle = self.np_random.uniform(joint_limit_low, joint_limit_high)"
        },
        {
            "comment": "The code snippet is part of a simulation class. It contains methods for resetting the state, setting up the camera view and projection matrices, and potentially deactivating suction if enabled. The setup_camera() method takes in parameters for camera positioning and field of view to configure the camera view. The setup_camera_rpy() method sets up the camera's orientation (roll, pitch, yaw) based on a target position, distance, rotation, field of view, and camera dimensions. The class is likely used in a simulated robotics environment for manipulation tasks.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":703-724",
            "content": "                p.resetJointState(obj_id, joint_idx, joint_angle, physicsClientId=self.id)\n    def reset(self):\n        p.restoreState(self.init_state, physicsClientId=self.id)\n        self.time_step = 0\n        self.success = False\n        if self.use_suction:\n            self.deactivate_suction()\n        return self._get_obs()\n    def setup_camera(self, camera_eye=[0.5, -0.75, 1.5], camera_target=[-0.2, 0, 0.75], fov=60, camera_width=640, camera_height=480):\n        self.camera_width = camera_width\n        self.camera_height = camera_height\n        self.view_matrix = p.computeViewMatrix(camera_eye, camera_target, [0, 0, 1], physicsClientId=self.id)\n        self.projection_matrix = p.computeProjectionMatrixFOV(fov, camera_width / camera_height, 0.01, 100, physicsClientId=self.id)\n    def setup_camera_rpy(self, camera_target=[0, 0, 0.3], distance=1.6, rpy=[0, -30, -30], fov=60, camera_width=640, camera_height=480):\n        self.camera_width = camera_width\n        self.camera_height = camera_height\n        if self.use_table:"
        },
        {
            "comment": "The code is setting up a camera view in the environment. If there's no specified target, it randomly centers at an object (excluding \"robot\", \"plane\", and \"init_table\"). The computed view and projection matrices are then used to render the image with OpenGL hardware renderer.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":725-742",
            "content": "            camera_target = np.array([0, 0, 0.3])\n        else:\n            for name in self.urdf_ids: # randomly center at an object\n                if name in ['robot', 'plane', 'init_table']: continue\n                obj_id = self.urdf_ids[name]\n                min_aabb, max_aabb = self.get_aabb(obj_id)\n                center = (min_aabb + max_aabb) / 2\n                camera_target = center \n                break\n        self.view_matrix = p.computeViewMatrixFromYawPitchRoll(camera_target, distance, rpy[2], rpy[1], rpy[0], 2, physicsClientId=self.id)\n        self.projection_matrix = p.computeProjectionMatrixFOV(fov, camera_width / camera_height, 0.01, 100, physicsClientId=self.id)\n    def render(self, mode=None):\n        assert self.view_matrix is not None, 'You must call env.setup_camera() or env.setup_camera_rpy() before getting a camera image'\n        w, h, img, depth, segmask = p.getCameraImage(self.camera_width, self.camera_height, \n            self.view_matrix, self.projection_matrix, \n            renderer=p.ER_BULLET_HARDWARE_OPENGL, "
        },
        {
            "comment": "The function returns an image and depth values, reshaping the input arrays. The take_step function handles None cases for gains and forces, ensuring they are lists of appropriate length. It then clips the action array within specified bounds before separating translation, rotation, and suction values.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":743-770",
            "content": "            physicsClientId=self.id)\n        img = np.reshape(img, (h, w, 4))[:, :, :3]\n        depth = np.reshape(depth, (h, w))\n        return img, depth\n    def take_step(self, actions, gains=None, forces=None):\n        if gains is None:\n            gains = [a.motor_gains for a in self.agents]\n        elif type(gains) not in (list, tuple): \n            gains = [gains]*len(self.agents)\n        if forces is None:\n            forces = [a.motor_forces for a in self.agents]\n        elif type(forces) not in (list, tuple):\n            forces = [forces]*len(self.agents)\n        action_index = 0\n        for i, agent in enumerate(self.agents):\n            agent_action_len = self.base_action_space.shape[0] \n            action = np.copy(actions[action_index:action_index+agent_action_len])\n            action_index += agent_action_len\n            action = np.clip(action, self.action_low, self.action_high)\n            translation = action[:3]\n            rotation = action[3:6]\n            suction = action[6]\n          "
        },
        {
            "comment": "The code sets a joint based on the agent's controllable joints and then retrieves the current joint angles. It checks for different translation modes and applies appropriate translations to the end-effector position. Additionally, it handles various rotation modes, including Euler angle and delta-axis/delta-euler-angle transformations.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":770-788",
            "content": "  joint = agent.right_end_effector if 'right' in agent.controllable_joints else agent.left_end_effector\n            agent_joint_angles = agent.get_joint_angles(agent.controllable_joint_indices)\n            ik_indices = [_ for _ in range(len(agent.right_arm_ik_indices))]\n            pos, orient = agent.get_pos_orient(joint)\n            # eef translation\n            if self.translation_mode == 'delta-translation':\n                pos += translation * self.max_translation\n            elif self.translation_mode == 'normalized-direct-translation':\n                pos = translation * self.scene_range + self.scene_center\n            elif self.translation_mode == 'direct-translation':\n                pos = translation \n            # eef rotation\n            if self.rotation_mode == 'euler-angle':\n                rotation = rotation * np.pi\n                orient = p.getQuaternionFromEuler(rotation)\n            elif 'delta-axis-angle' in self.rotation_mode or 'delta-euler-angle' in self.rotation_mode:\n                orient = self.apply_delta_rotation(rotation, orient)"
        },
        {
            "comment": "The code sets the agent's joint angles using inverse kinematics, controls the agent's joint movements based on given gains and forces, manages gripper position depending on suction activation, and applies delta rotation to orient the agent. The rotation mode uses a maximum angle limit for rotations.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":790-810",
            "content": "            agent_joint_angles = agent.ik(joint, pos, orient, ik_indices, max_iterations=200, use_current_as_rest=False)\n            agent.control(agent.controllable_joint_indices, agent_joint_angles, gains[i], forces[i])\n            # gripper\n            if not self.use_suction:\n                agent.set_gripper_open_position(agent.right_gripper_indices, [suction])\n            else:\n                if suction >= 0: self.activate_suction()\n                else: self.deactivate_suction()\n        for _ in range(self.frameskip):\n            p.stepSimulation(physicsClientId=self.id)                   \n    def apply_delta_rotation(self, delta_rotation, orient):\n        if 'delta-axis-angle' in self.rotation_mode:\n            dtheta = np.linalg.norm(delta_rotation)\n            if dtheta > 0:\n                delta_rotation = delta_rotation / dtheta\n                dtheta = dtheta * self.max_rotation_angle / np.sqrt(3)\n                delta_rotation_matrix = R.from_rotvec(delta_rotation * dtheta).as_matrix()\n            else:"
        },
        {
            "comment": "This code performs rotation and suction activation for a robot manipulator. It handles three types of rotations: delta-axis-angle-local, delta-axis-angle-global, and delta-euler-angle. The activate_suction function ensures the suction is attached to the correct end effector.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":811-831",
            "content": "                delta_rotation_matrix = np.eye(3)\n            current_matrix = np.array(p.getMatrixFromQuaternion(orient)).reshape(3, 3)\n            if self.rotation_mode == 'delta-axis-angle-local':\n                new_rotation = current_matrix @ delta_rotation_matrix\n            elif self.rotation_mode == 'delta-axis-angle-global':\n                new_rotation = delta_rotation_matrix @ current_matrix\n            orient = R.from_matrix(new_rotation).as_quat()\n        elif self.rotation_mode == 'delta-euler-angle':\n            euler_angle = delta_rotation / np.sqrt(3) * self.max_rotation_angle\n            delta_quaternion = p.getQuaternionFromEuler(euler_angle)\n            orient = delta_quaternion * orient\n        return orient\n    def activate_suction(self):\n        if not self.activated:\n            # assume the suction is attached to the right end effector\n            suction_id = self.suction_id\n            points = p.getContactPoints(bodyA=self.robot.body, linkIndexA=suction_id, physicsClientId=self.id)"
        },
        {
            "comment": "This code handles contact between suction and a rigid object. It counts the number of contacts for each object and link, then finds the object with the most contacts. It retrieves the robot's body pose and the pose of the contacted object's link.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":832-850",
            "content": "            if points:\n                # Handle contact between suction with a rigid object.\n                contact_object_id_link_cnts = defaultdict(int)\n                for point in points:\n                    obj_id, contact_link, contact_position_on_obj = point[2], point[4], point[6]\n                    if obj_id == self.urdf_ids['plane'] or obj_id == self.robot.body:\n                        pass\n                    else:\n                        contact_object_id_link_cnts[(obj_id, contact_link)] += 1\n                if len(contact_object_id_link_cnts) > 0:\n                    # find the object that has the most contact points\n                    obj_id, contact_link = max(contact_object_id_link_cnts.items(), key=lambda x: x[1])[0]\n                    # print(\"contact with object: \", obj_id, contact_link)\n                    body_pose = p.getLinkState(self.robot.body, suction_id, physicsClientId=self.id)\n                    if contact_link >= 0:\n                        obj_link_pose = p.getLinkState(obj_id, contact_link, physicsClientId=self.id)"
        },
        {
            "comment": "This code checks if an object is in the suction cup's field of view. If not, it retrieves the object's position and orientation relative to the robot's base. It then calculates the transformation from the world coordinate system to the object and from the object to the suction cup. After that, it creates a constraint between the suction cup and the object using the calculated transformations.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":851-869",
            "content": "                    else:\n                        obj_link_pose = p.getBasePositionAndOrientation(obj_id, physicsClientId=self.id)\n                    world_to_body = p.invertTransform(body_pose[0], body_pose[1])\n                    obj_to_body = p.multiplyTransforms(world_to_body[0],\n                                                        world_to_body[1],\n                                                        obj_link_pose[0], obj_link_pose[1])\n                    suction_to_obj = p.invertTransform(obj_to_body[0], obj_to_body[1])\n                    self.create_suction_constraint(obj_id, contact_link, suction_to_obj)\n                    self.activated = True\n                    self.suction_obj_id = obj_id\n                    self.suction_contact_link = contact_link\n                    self.suction_to_obj_pose = suction_to_obj\n    def create_suction_constraint(self, suction_obj_id, suction_contact_link, suction_to_obj_pose):\n        suction_id = self.suction_id\n        self.contact_constraint = p.createConstraint("
        },
        {
            "comment": "The code sets a fixed joint between the parent body (robot) and child link (suction object), configuring the joint properties, positions, and orientations. It then updates the maximum force for the constraint and deactivates the suction if needed. The code also handles typing errors and takes steps during simulation.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":870-895",
            "content": "            parentBodyUniqueId=self.robot.body,\n            parentLinkIndex=suction_id,\n            childBodyUniqueId=suction_obj_id,\n            childLinkIndex=suction_contact_link,\n            jointType=p.JOINT_FIXED,\n            jointAxis=(0, 0, 0), \n            parentFramePosition=(0, 0, 0),\n            parentFrameOrientation=(0, 0, 0),\n            childFramePosition=suction_to_obj_pose[0],\n            childFrameOrientation=suction_to_obj_pose[1], \n            physicsClientId=self.id)\n        p.changeConstraint(self.contact_constraint, maxForce=5000, physicsClientId=self.id)\n    def deactivate_suction(self):\n        self.activated = False\n        if self.contact_constraint is not None:\n            p.removeConstraint(self.contact_constraint, physicsClientId=self.id)\n            self.contact_constraint = None\n    def step(self, action):\n        self.time_step += 1        \n        self.take_step(action)\n        obs = self._get_obs()                \n        # to handle some stupid typing error in early prompts"
        },
        {
            "comment": "The code is defining the observation space for RL policy learning, which includes object positions and orientations, object bounding boxes, articulated object joint angles, articulated object link position/orientation, robot base position, end-effector position/orientation, and gripper state. It initializes the observation vector with zeros and iterates through a dictionary of object IDs to populate it based on their respective properties. The code also handles computing rewards and successes, setting done flag based on time step reaching horizon, and returning obs, reward, done, and info.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":896-921",
            "content": "        try:\n            reward, success = self._compute_reward() \n        except:\n            reward, success = self.compute_reward()\n        self.success = success\n        done = self.time_step == self.horizon\n        info = self._get_info()\n        return obs, reward, done, info\n    def _get_info(self):\n        return {}\n    def _get_obs(self):\n        ### For RL policy learning, observation space includes:\n        # 1. object positions and orientations (6 * num_objects)\n        # 2. object min and max bounding box (6 * num_objects)\n        # 3. articulated object joint angles (num_objects * num_joints) \n        # 4. articulated object link position and orientation (num_objects * num_joints * 6) \n        # 5. robot base position (xy)\n        # 6. robot end-effector position and orientation (6)\n        # 7. gripper suction activated/deactivate or gripper joint angle (if not using suction gripper) (1)\n        obs = np.zeros(self.base_observation_space.shape[0])\n        cnt = 0\n        for name, id in self.urdf_ids.items():"
        },
        {
            "comment": "This code is obtaining the base position and orientation of specific entities in a simulation, normalizing their positions, and storing them in an observation (obs) array. It ignores distractor entities and urdf types not set as 'urdf'.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":922-946",
            "content": "            if name == 'plane' or name == 'robot':\n                continue\n            if self.is_distractor[name]:\n                continue\n            pos, orient = p.getBasePositionAndOrientation(id, physicsClientId=self.id)\n            euler_angle = p.getEulerFromQuaternion(orient)\n            obs[cnt:cnt+3] = self.normalize_position(pos)\n            obs[cnt+3:cnt+6] = euler_angle\n            cnt += 6\n        for name, id in self.urdf_ids.items():\n            if name == 'plane' or name == 'robot':\n                continue\n            if self.is_distractor[name]:\n                continue\n            min_aabb, max_aabb = self.get_aabb(id)\n            obs[cnt:cnt+3] = self.normalize_position(min_aabb)\n            obs[cnt+3:cnt+6] = self.normalize_position(max_aabb)\n            cnt += 6\n        for name in self.urdf_types:\n            if self.urdf_types[name] == 'urdf' and not self.is_distractor[name]:\n                num_joints = p.getNumJoints(self.urdf_ids[name], physicsClientId=self.id)\n                for joint_idx in range(num_joints):"
        },
        {
            "comment": "This code retrieves joint angles, link positions and orientations, and end-effector information from a robot in the physics engine. It stores this data in an observation array for future use.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":947-965",
            "content": "                    joint_angle = p.getJointState(self.urdf_ids[name], joint_idx, physicsClientId=self.id)[0]\n                    obs[cnt] = joint_angle\n                    cnt += 1\n                    link_pos, link_orient = p.getLinkState(self.urdf_ids[name], joint_idx, physicsClientId=self.id)[:2]\n                    link_pos = self.normalize_position(link_pos)\n                    link_euler_angle = p.getEulerFromQuaternion(link_orient)\n                    obs[cnt:cnt+3] = link_pos\n                    obs[cnt+3:cnt+6] = link_euler_angle\n                    cnt += 6\n        robot_base_pos, robot_base_orient = self.robot.get_base_pos_orient()\n        robot_base_pos = self.normalize_position(robot_base_pos)\n        obs[cnt:cnt+2] = robot_base_pos[:2]\n        cnt += 2\n        robot_eef_pos, robot_eef_orient = self.robot.get_pos_orient(self.robot.right_end_effector)\n        robot_eef_euler_angle = p.getEulerFromQuaternion(robot_eef_orient)\n        obs[cnt:cnt+3] = self.normalize_position(robot_eef_pos)\n        obs[cnt+3:cnt+6] = robot_eef_euler_angle"
        },
        {
            "comment": "This code gets the joint angle of a robot's gripper and adds it to an observation array, then disconnects from the physics engine. If the suction is not being used, it gets the joint angles for both left and right fingers. Otherwise, it simply adds whether the suction is activated or not.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/manipulation/sim.py\":966-985",
            "content": "        cnt += 6\n        if not self.use_suction:\n            # get joint angle of the gripper\n            left_finger_joint_angle = p.getJointState(self.robot.body, self.robot.right_gripper_indices[0], physicsClientId=self.id)[0]\n            right_finger_joint_angle = p.getJointState(self.robot.body, self.robot.right_gripper_indices[1], physicsClientId=self.id)[0]\n            obs[cnt] = left_finger_joint_angle\n            obs[cnt+1] = right_finger_joint_angle\n            cnt += 2\n        else:\n            obs[cnt] = int(self.activated)\n            cnt += 1\n        return obs\n    def disconnect(self):\n        p.disconnect(self.id)\n    def close(self):\n        p.disconnect(self.id)"
        }
    ]
}