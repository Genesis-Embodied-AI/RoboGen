{
    "summary": "The code performs complex tasks, writes meta information to JSON, detects GIF files, executes trials, saves results, selects the best outcome, and outputs in text/GIF formats. It also allows customizable configurations for features in a training algorithm and multiple task execution options.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and defining a function named \"execute_multiple_try\" that takes in various parameters such as task configuration path, time string, resume status, training algorithm, gui flag, randomize flag, bard usage, gpt size usage, gpt joint angle initialization, object ID, motion planning usage, and distractor usage. The function seems to be related to executing tasks with some level of complexity, potentially in a robotics or AI context.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":0-22",
            "content": "import yaml\nfrom execute import execute_primitive\nfrom manipulation.utils import save_numpy_as_gif, load_gif\nimport subprocess\nimport numpy as np\nimport time, datetime\nimport os\nimport json\ndef execute_multiple_try(\n            task_config_path, \n            time_string=None, resume=False, # these two are combined for resume training.\n            training_algo='cem', \n            gui=False, \n            randomize=False, # whether to randomize the initial state of the environment.\n            use_bard=True, # whether to use the bard to verify the retrieved objects.\n            use_gpt_size=True, # whether to use the size from gpt.\n            use_gpt_joint_angle=True, # whether to initialize the joint angle from gpt.\n            use_gpt_spatial_relationship=True, # whether to use the spatial relationship from gpt.\n            obj_id=0, # which object to use from the list of possible objects.\n            use_motion_planning=True,\n            use_distractor=False,\n            skip=[], # which substeps to skip."
        },
        {
            "comment": "This code segment is responsible for initializing and preparing the necessary paths for an experiment, including creating the required directories if they do not exist. It reads configuration data from a task_config file, extracts the solution path, creates the solution and experiment paths, and stores meta-information such as which models are being used, whether distractors are used, etc.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":23-56",
            "content": "            num_try=8,\n):\n    if time_string is None:\n        ts = time.time()\n        time_string = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n    meta_info = {\n        \"using_motion_planning\": use_motion_planning,\n        \"using_bard\": use_bard,\n        \"using_gpt_size\": use_gpt_size,\n        \"using_gpt_joint_angle\": use_gpt_joint_angle,\n        \"using_gpt_spatial_relationship\": use_gpt_spatial_relationship,\n        \"obj_id\": obj_id,\n        \"use_distractor\": use_distractor\n    }\n    all_last_state_files = []\n    with open(task_config_path, 'r') as file:\n        task_config = yaml.safe_load(file)\n    solution_path = None\n    for obj in task_config:\n        if \"solution_path\" in obj:\n            solution_path = obj[\"solution_path\"]\n            break\n    if not os.path.exists(solution_path):\n        os.makedirs(solution_path, exist_ok=True)\n    experiment_path = os.path.join(solution_path, \"experiment\")\n    if not os.path.exists(experiment_path):\n        os.makedirs(experiment_path, exist_ok=True)"
        },
        {
            "comment": "This code writes meta information to a JSON file, reads substeps and substep types from two separate files, and retrieves action spaces for all steps. It also skips certain substeps if specified in the skip list, and stores the RGB values of the environment at each step into a list called \"all_rgbs\".",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":57-79",
            "content": "    with open(os.path.join(experiment_path, \"meta_info_{}.json\".format(time_string)), 'w') as f:\n        json.dump(meta_info, f)\n    all_substeps = os.path.join(solution_path, \"substeps.txt\")\n    with open(all_substeps, 'r') as f:\n        substeps = f.readlines()\n    print(\"all substeps:\\n {}\".format(\"\".join(substeps)))\n    substep_types = os.path.join(solution_path, \"substep_types.txt\")\n    with open(substep_types, 'r') as f:\n        substep_types = f.readlines()\n    print(\"all substep types:\\n {}\".format(\"\".join(substep_types)))\n    action_spaces = os.path.join(solution_path, \"action_spaces.txt\")\n    with open(action_spaces, 'r') as f:\n        action_spaces = f.readlines()\n    print(\"all action spaces:\\n {}\".format(\"\".join(action_spaces)))\n    last_restore_state_file = None\n    all_rgbs = []\n    for step_idx, (substep, substep_type, action_space) in enumerate(zip(substeps, substep_types, action_spaces)):\n        if (skip is not None) and (step_idx < len(skip)) and int(skip[step_idx]):\n            print(\"skip substep: \", substep)"
        },
        {
            "comment": "This code segment handles the execution of substep for a particular primitive action type in a long-horizon task. It checks if the final state already exists and skips further execution if it does, considering resume option. It also ensures proper file directories are created and maintains a sorted list of pickle files to restore from the latest checkpoint.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":80-98",
            "content": "            continue\n        substep = substep.lstrip().rstrip()\n        substep_type = substep_type.lstrip().rstrip()\n        action_space = action_space.lstrip().rstrip()\n        print(\"executing for substep:\\n {} {}\".format(substep, substep_type))\n        if substep_type == \"primitive\" and use_motion_planning:\n            save_path = os.path.join(solution_path, \"primitive_states\", time_string, substep.replace(\" \", \"_\"))\n            if not os.path.exists(save_path):\n                os.makedirs(save_path, exist_ok=True)\n            all_files = os.listdir(save_path)\n            all_pkl_files = [f for f in all_files if f.endswith(\".pkl\")]\n            gif_path = os.path.join(save_path, \"execute.gif\")\n            if os.path.exists(gif_path) and resume:\n                print(\"final state already exists, skip {}\".format(substep))\n                sorted_pkl_files = sorted(all_pkl_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n                last_restore_state_file = os.path.join(save_path, sorted_pkl_files[-1])"
        },
        {
            "comment": "The code snippet checks if a GIF file exists at the specified path. If it does, the GIF frames are appended to all_rgbs. Otherwise, it executes a primitive task based on the provided configuration and stores the resulting RGB frames in rgbs. The last restore state is saved for future reference. If the substep type is \"reward\", multiple instances of execute.py are called to learn the reward.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":99-114",
            "content": "                all_rgbs.extend(load_gif(gif_path))\n            else:\n                rgbs, states = execute_primitive(task_config_path, solution_path, substep, last_restore_state_file, save_path, \n                                                 gui=gui, randomize=randomize, use_bard=use_bard, obj_id=obj_id, \n                                                 use_gpt_size=use_gpt_size, use_gpt_joint_angle=use_gpt_joint_angle,\n                                                 use_gpt_spatial_relationship=use_gpt_spatial_relationship,\n                                                 use_distractor=use_distractor)\n                last_restore_state_file = states[-1]\n                all_rgbs.extend(rgbs)\n                save_numpy_as_gif(np.array(rgbs), \"{}/{}.gif\".format(save_path, \"execute\"))\n        if substep_type == \"reward\":\n            save_path = os.path.join(solution_path, training_algo, time_string, substep.replace(\" \", \"_\"))\n            # call execute.py multiple times to learn the reward\n            processes = []"
        },
        {
            "comment": "The code executes multiple trials, spawns subprocesses to learn and save results, waits for them to complete, selects the best result from saved data.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":115-135",
            "content": "            for learning_try in range(num_try):\n                try_save_path = os.path.join(save_path, \"try_\" + str(learning_try))\n                if not os.path.exists(try_save_path):\n                    os.makedirs(try_save_path, exist_ok=True)\n                cmd = [\"python\", \"execute.py\", \"--task_config_path\", task_config_path, \"--only_learn_substep\", str(step_idx), \"--reward_learning_save_path\", try_save_path, \n                       \"--last_restore_state_file\", last_restore_state_file]\n                # Spawn the subprocesses\n                proc = subprocess.Popen(cmd)\n                processes.append(proc)\n                time.sleep(5)\n            # Wait for all subprocesses to finish\n            for proc in processes:\n                proc.wait()\n            best_return = -np.inf\n            best_idx = None\n            for learning_try in range(num_try):\n                best_state_path = os.path.join(save_path, \"try_\" + str(learning_try), \"best_state\")\n                all_return_files = [x for x in os.listdir(best_state_path) if x.endswith(\".txt\")]"
        },
        {
            "comment": "This code block retrieves the highest return from a list, updates the best return if necessary, and then performs several operations. It extracts the best state path, lists all .pkl files in that directory, sorts them by their numerical prefix, gets the last one, appends corresponding frames to all_rgbs using load_gif function, copies the best state path and model directory to save_path, and adds the last restore state file path to all_last_state_files.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":136-151",
            "content": "                all_return = [float(x.split(\"_\")[1][:-4]) for x in all_return_files]\n                if len(all_return) > 0:\n                    highest_return = max(all_return)\n                    if highest_return > best_return:\n                        best_return = highest_return\n                        best_idx = learning_try\n            best_state_path = os.path.join(save_path, \"try_\" + str(best_idx), \"best_state\")\n            all_pkl_files = [x for x in os.listdir(best_state_path) if x.endswith(\".pkl\")]\n            all_pkl_files = sorted(all_pkl_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n            last_restore_state_file = os.path.join(best_state_path, all_pkl_files[-1])\n            all_rgbs.extend(load_gif(os.path.join(best_state_path, \"best.gif\")))\n            os.system(\"cp -r {} {}\".format(best_state_path, save_path + \"/\"))\n            os.system(\"cp -r {} {}\".format(os.path.join(save_path, \"try_\" + str(best_idx),  \"best_model\"), save_path + \"/\"))\n        all_last_state_files.append(str(last_restore_state_file))"
        },
        {
            "comment": "This code segment saves the final output of a simulation into two formats: text and GIF. It accepts various parameters like task configuration path, training algorithm, time string for resuming, GUI usage, object randomization, object ID, and usage of BAR filtering. The saved text file contains all last states recorded during the experiment at each timestep, while the GIF is a visual representation of the simulation's final state named \"all\" with a timestamp-based label.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":152-169",
            "content": "        with open(os.path.join(experiment_path, \"all_last_state_files_{}.txt\".format(time_string)), 'w') as f:\n            f.write(\"\\n\".join(all_last_state_files))\n    # save the final gif\n    save_path = os.path.join(solution_path)\n    save_numpy_as_gif(np.array(all_rgbs), \"{}/{}-{}.gif\".format(save_path, \"all\", time_string))\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--task_config_path', type=str, default=None)\n    parser.add_argument('--training_algo', type=str, default=\"RL_sac\")\n    parser.add_argument('--resume', type=int, default=0)\n    parser.add_argument('--time_string', type=str, default=None) # which folder to use to resume training.\n    parser.add_argument('--gui', type=int, default=0) \n    parser.add_argument('--randomize', type=int, default=1) # whether to randomize roation of objects in the scene.\n    parser.add_argument('--obj_id', type=int, default=None) # which object from the list of possible objects to use.\n    parser.add_argument('--use_bard', type=int, default=1) # whether to use bard filtered objects."
        },
        {
            "comment": "This code sets arguments for different features to use in the training and execution process. These include using size from GPT, spatial relationships, initial joint angles, whether to train or just build the scene, motion planning, distractors, skipping specific tasks, and number of tries. The function parse_args() is used to extract these arguments and task_config_path is assigned the argument's value for this path. Finally, execute_multiple_try is called with these arguments.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":170-182",
            "content": "    parser.add_argument('--use_gpt_size', type=int, default=1) # whether to use size outputted from gpt.\n    parser.add_argument('--use_gpt_spatial_relationship', type=int, default=1) # whether to use gpt spatial relationship.\n    parser.add_argument('--use_gpt_joint_angle', type=int, default=1) # whether to use initial joint angle output from gpt.\n    parser.add_argument('--run_training', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--use_motion_planning', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--use_distractor', type=int, default=1) # if to train or just to build the scene.\n    parser.add_argument('--skip', nargs=\"+\", default=[]) # if to train or just to build the scene.\n    parser.add_argument('--num_try', type=int, default=5) # if to train or just to build the scene.\n    args = parser.parse_args()\n    task_config_path = args.task_config_path\n    execute_multiple_try(task_config_path, \n            resume=args.resume, "
        },
        {
            "comment": "This code snippet is creating an instance of a class with multiple parameters. These arguments control the training algorithm, user interface, randomization, Bard usage, GPT-related features, object ID, motion planning, distractor usage, and number of attempts. The purpose is to execute long-horizon tasks with various customizable configurations.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/execute_long_horizon.py\":183-196",
            "content": "            training_algo=args.training_algo, \n            time_string=args.time_string, \n            gui=args.gui, \n            randomize=args.randomize,\n            use_bard=args.use_bard,\n            use_gpt_size=args.use_gpt_size,\n            use_gpt_joint_angle=args.use_gpt_joint_angle,\n            use_gpt_spatial_relationship=args.use_gpt_spatial_relationship,\n            obj_id=args.obj_id,\n            use_motion_planning=args.use_motion_planning,\n            use_distractor=args.use_distractor,\n            skip=args.skip,\n            num_try=args.num_try,\n    )"
        }
    ]
}