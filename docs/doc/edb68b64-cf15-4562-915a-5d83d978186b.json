{
    "summary": "The code imports libraries, defines task scene fields, addresses collision avoidance, generates responses, and uses Partnet Mobility. It saves the original configuration in YAML format and appends a dictionary to ori_config with distractor_config_path.",
    "details": [
        {
            "comment": "Code imports necessary libraries and defines user_contents as a list containing task description and configuration details for a robotic arm task scene.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":0-19",
            "content": "import json\nfrom gpt_4.query import query\nimport os\nimport copy\nimport yaml\nimport numpy as np\nimport torch\nimport json\nfrom gpt_4.verification import check_text_similarity\nfrom gpt_4.prompts.utils import parse_response_to_get_yaml\nuser_contents = [\n\"\"\"\nGiven a task, which is for a mobile Franka panda robotic arm to learn a manipulation skill in the simulator, your goal is to add more objects into the task scene such that the scene looks more realistic. The Franka panda arm is mounted on a floor, at location (1, 1, 0). It can move freely on the floor. The z axis is the gravity axis. \nThe input to you includes the following:\nTask name, task description, the essential objects involved in the task, and a config describing the current task scene, which contains only the essential objects needed for the task. The config is a yaml file in the following format:\n```yaml \n- use_table: whether the task requires using a table. This should be decided based on common sense. If a table is used, its location will be fixed at (0, 0, 0). The height of the table will be 0.6m. "
        },
        {
            "comment": "This code snippet outlines the required fields for an object involved in a task, such as its type (mesh), name, size (scale), language description, path to mesh, whether it needs to be on the table, and its center location. These fields help define objects for a simulator or to search an existing database of objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":20-27",
            "content": "# for each object involved in the task, we need to specify the following fields for it.\n- type: mesh\n  name: name of the object, so it can be referred to in the simulator\n  size: describe the scale of the object mesh using 1 number in meters. The scale should match real everyday objects. E.g., an apple is of scale 0.08m. You can think of the scale to be the longest dimension of the object. \n  lang: this should be a language description of the mesh. The language should be a bit detailed, such that the language description can be used to search an existing database of objects to find the object.\n  path: this can be a string showing the path to the mesh of the object. \n  on_table: whether the object needs to be placed on the table (if there is a table needed for the task). This should be based on common sense and the requirement of the task.     \n  center: the location of the object center. If there isn't a table needed for the task or the object does not need to be on the table, this center sho"
        },
        {
            "comment": "This code discusses the concept of specifying a location for an object in either world or table coordinate system to avoid collision with other objects. The goal is to provide a more complex and realistic scene for the robot to learn from, while ensuring there are no collisions between different objects.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":27-37",
            "content": "uld be expressed in the world coordinate system. If there is a table in the task and the object needs to be placed on the table, this center should be expressed in terms of the table coordinate, where (0, 0, 0) is the lower corner of the table, and (1, 1, 1) is the higher corner of the table. In either case, you should try to specify a location such that there is no collision between objects.\n```\nYour task is to think about what other distractor objects can be added into the scene to make the scene more complex and realistic for the robot to learn the task. These distractor objects are not necessary for the task itself, but their existence makes the scene look more interesting and complex. You should output the distractor objects using the same format as the input yaml file. You should try to put these distractor objects at locations such that they don\u2019t collide with objects already in the scene. \nHere is one example:\nInput:\nTask name: Heat up a bowl of soup in the microwave\nTask description"
        },
        {
            "comment": "The code introduces two new objects, a plate and a sponge, to accompany the microwave and bowl of soup on the table.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":37-73",
            "content": ": The robot will grab the soup and move it into the microwave, and then set the temperature to heat it.\nObjects involved: Microwave, a bowl of soup\nConfig:\n```yaml\n-   use_table: true\n-   center: (0.3, 0.7, 0)\n    lang: A standard microwave with a turntable and digital timer\n    name: Microwave\n    on_table: true\n    path: microwave.urdf\n    size: 0.6\n    type: urdf\n-   center: (0.2, 0.2, 0)\n    lang: A ceramic bowl full of soup\n    name: Bowl of Soup\n    on_table: true\n    path: bowl_soup.obj\n    size: 0.15\n    type: mesh\n```\nOutput: \n```yaml\n- name: plate # a plate is a common object placed when there is microwave and bowl of soup, in a kitchen setup\n  lang: a common kitchen plate\n  on_table: True\n  center: (0.8, 0.8, 0)\n  type: mesh\n  path: \"plate.obj\"\n  size: 0.15 # a plate is usually of scale 0.15m\n- name: sponge # a sponge is a common object placed when there is microwave and bowl of soup, in a kitchen setup\n  lang: a common sponge\n  on_table: True\n  center: (0.5, 0.2, 0)\n  type: mesh\n  path: \"sponge.obj\"\n  size: 0.1 # a sponge is usually of scale 0.1m"
        },
        {
            "comment": "The code defines a distractor object for an AI task, specifying its name, language, placement, size, and type. It retrieves the original task configuration file, extracts the task name and description, and reads an existing response file if available. The purpose is to create a distracting object to be placed in the scene during the AI task execution.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":74-106",
            "content": "- name: Oven # a oven is a common object placed when there is microwave and bowl of soup, in a kitchen setup\n  lang: a kitchen oven\n  on_table: False # an oven is usually a standalone object on the floor\n  center: (1.8, 0.5, 0) # remember robot is at (1, 1, 0) and table is at (0, 0, 0). So the oven is placed at (1.8, 0.5, 0) in the world coordinate system to avoid collision with other objects.\n  type: mesh\n  path: \"oven.obj\"\n  size: 0.8 # an oven is usually of scale 0.8m\n```\nCan you do it for the following task:\n\"\"\"\n]\nassistant_contents = [\n]\ndef generate_distractor(task_config, temperature_dict, model_dict):\n    parent_folder = os.path.dirname(task_config)\n    existing_response = os.path.join(parent_folder, \"gpt_response/task_generation.json\")\n    ori_config = None\n    with open(task_config, 'r') as f:\n        ori_config = yaml.safe_load(f)\n    task_name = None\n    task_description = None\n    for obj in ori_config:\n        if \"task_name\" in obj:\n            task_name = obj[\"task_name\"]\n        if \"task_description\" in obj:"
        },
        {
            "comment": "The code creates tasks with multiple descriptions and configurations by copying the original configuration, removing specific keys, and saving them as new files. It then formats the task description for file naming.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":107-141",
            "content": "            task_description = obj[\"task_description\"]\n    task_number = 1\n    task_names = [task_name]\n    task_descriptions = [task_description]\n    input = \"\"\"\nTask name: {}\nTask description: {}\nInitial config:\n```yaml\n{}\n```\n\"\"\"\n    for idx in range(task_number):\n        task_name = task_names[idx]\n        task_description = task_descriptions[idx]\n        copied_config = copy.deepcopy(ori_config)\n        new_yaml = []\n        for obj in copied_config:\n            if \"task_description\" in obj or \"solution_path\" in obj or \"spatial_relationships\" in obj or \"set_joint_angle_object_name\" in obj:\n                continue\n            if \"uid\" in obj:\n                del obj[\"uid\"]\n            if \"all_uid\" in obj:\n                del obj[\"all_uid\"]\n            if \"reward_asset_path\" in obj.keys():\n                del obj[\"reward_asset_path\"]\n            new_yaml.append(obj)\n        description = f\"{task_description}\".replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n        save_name =  description + '.yaml'"
        },
        {
            "comment": "This code is creating a distractor for a GPT-4 model. It checks if the distractor file already exists, and if not, it generates an initial configuration and fills in user input with task details. Then it queries the GPT-4 model to obtain a response, parses that response into a YAML format, and saves both the original response and parsed YAML as separate files.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":142-159",
            "content": "        distractor_save_path = os.path.join(parent_folder, save_name.replace(\".yaml\", \"_distractor.yaml\"))\n        if os.path.exists(distractor_save_path):\n            continue\n        initial_config = yaml.dump(new_yaml)\n        input_filled = copy.deepcopy(input)\n        input_filled = input_filled.format(task_name, task_description, initial_config)\n        input_filled = user_contents[-1] + input_filled\n        save_path = os.path.join(parent_folder, \"gpt_response/distractor-{}.json\".format(task_name.replace(\" \", \"_\")))\n        system = \"You are a helpful assistant.\"\n        task_response = query(system, [input_filled], [], save_path=save_path, debug=False, temperature=0.2)\n        size_save_path = os.path.join(parent_folder, \"gpt_response/size_distractor_{}.json\".format(task_name))\n        response = task_response.split(\"\\n\")\n        parsed_yaml, _ = parse_response_to_get_yaml(response, task_description, save_path=size_save_path, \n                            temperature=temperature_dict[\"size\"], model=model_dict[\"size\"])"
        },
        {
            "comment": "This code performs post-processing on parsed objects. If an object is similar enough to a Sapian object, it retrieves the object from Partnet Mobility. It first loads category embeddings and creates a dictionary of Sapian object categories. Then, for each object in the parsed list, it checks text similarity using the embeddings, finds the most similar Sapian category, and if the similarity is above 0.95, sets the object type to 'urdf' and name to the best category, then retrieves a random reward asset path from the Sapian object dictionary.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":161-178",
            "content": "        # some post processing: if the object is close enough to sapian object, we retrieve it from partnet mobility\n        sapian_obj_embeddings = torch.load(\"objaverse_utils/data/partnet_mobility_category_embeddings.pt\")\n        sapian_object_dict = None\n        with open(\"data/partnet_mobility_dict.json\", 'r') as f:\n            sapian_object_dict = json.load(f)\n        sapian_object_categories = list(sapian_object_dict.keys())\n        for obj in parsed_yaml:\n            name = obj['name']\n            similarity = check_text_similarity(name, check_embeddings=sapian_obj_embeddings)\n            max_similarity = np.max(similarity)\n            best_category = sapian_object_categories[np.argmax(similarity)]\n            if max_similarity > 0.95:\n                # retrieve the object from partnet mobility\n                obj['type'] = 'urdf'\n                obj['name'] = best_category\n                object_list = sapian_object_dict[best_category]\n                obj['reward_asset_path'] = object_list[np.random.randint(len(object_list))]"
        },
        {
            "comment": "The code appends a dictionary to ori_config with distractor_config_path, writes the original configuration to task_config file, and writes the parsed YAML to distractor_save_path.",
            "location": "\"/media/root/Prima/works/RoboGen/docs/src/gpt_4/prompts/prompt_distractor.py\":180-186",
            "content": "        ori_config.append(dict(distractor_config_path=distractor_save_path))\n        with open(task_config, 'w') as f:\n            yaml.dump(ori_config, f, indent=4)\n        with open(distractor_save_path, 'w') as f:\n            yaml.dump(parsed_yaml, f, indent=4)"
        }
    ]
}